

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/wallhaven-j5kjgy_1920x1080.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Jie">
  <meta name="keywords" content="">
  
    <meta name="description" content="TensorFlow 官网Keras 文档 介绍TensorFlow 是 Google 开发的开源深度学习框架, 可用于计算机视觉, 自然语言处理等领域. 安装1pip install tensorflow  注意 TensorFlow 2.x 官方预编译包当前只支持:  CPython 3.8 ‑ 3.11（Linux&#x2F;macOS&#x2F;Windows） CPython 3.12">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow-基本使用">
<meta property="og:url" content="http://example.com/2025/07/12/TensorFlow-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="TensorFlow 官网Keras 文档 介绍TensorFlow 是 Google 开发的开源深度学习框架, 可用于计算机视觉, 自然语言处理等领域. 安装1pip install tensorflow  注意 TensorFlow 2.x 官方预编译包当前只支持:  CPython 3.8 ‑ 3.11（Linux&#x2F;macOS&#x2F;Windows） CPython 3.12">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/deep-learning-layer-example.png">
<meta property="og:image" content="http://example.com/img/deep-learning-dense-layer-example.png">
<meta property="og:image" content="http://example.com/img/deep-learning-dropout-50-persent-example.png">
<meta property="og:image" content="http://example.com/img/deep-learning-standard-distribution-example.png">
<meta property="og:image" content="http://example.com/img/deep-learning-fitting-nonlinear-relationship.png">
<meta property="og:image" content="http://example.com/img/deep-learning-sigmoid-example.png">
<meta property="og:image" content="http://example.com/img/deep-learning-tanh-example.png">
<meta property="og:image" content="http://example.com/img/deep-learning-rectified-linear-unit-example.png">
<meta property="og:image" content="http://example.com/img/deep-learning-cross-entropy-accuracy-example.png">
<meta property="article:published_time" content="2025-07-12T06:00:17.000Z">
<meta property="article:modified_time" content="2025-07-14T08:26:07.468Z">
<meta property="article:author" content="Jie">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/deep-learning-layer-example.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>TensorFlow-基本使用 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  



  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Jie</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/SteinsGate_all.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="TensorFlow-基本使用"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-07-12 14:00" pubdate>
          2025年7月12日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          58 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">TensorFlow-基本使用</h1>
            
            
              <div class="markdown-body">
                
                <p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/">TensorFlow 官网</a><br><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/">Keras 文档</a></p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>TensorFlow 是 Google 开发的开源深度学习框架, 可用于计算机视觉, 自然语言处理等领域.</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">pip install tensorflow<br></code></pre></td></tr></table></figure>

<p>注意 TensorFlow 2.x 官方预编译包当前只支持:</p>
<ul>
<li>CPython 3.8 ‑ 3.11（Linux&#x2F;macOS&#x2F;Windows）</li>
<li>CPython 3.12 尚未提供官方 wheel</li>
</ul>
<p>可以用 <code>pyenv</code> 来安装对应版本 python:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">pyenv install 3.11.10<br></code></pre></td></tr></table></figure>

<p>或者用 <code>venv</code>, <code>conda</code> 等环境来管理.</p>
<h2 id="导入"><a href="#导入" class="headerlink" title="导入"></a>导入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br></code></pre></td></tr></table></figure>

<h1 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h1><h2 id="Keras"><a href="#Keras" class="headerlink" title="Keras"></a>Keras</h2><p>Keras 是一个高级神经网络 API, 最初由 Francois Chollet 开发, 现已集成到 TensorFlow 中.</p>
<p>Keras 源自希腊语单词, 意为 “角”, “号角”, 象征 “传递信号”, 暗指它是一个连接用户与底层深度学习框架的接口.</p>
<p>Keras 的 API 设计简单, 可以用少量代码构建复杂神经网络, 提供模块化结构.</p>
<h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><p>Tensor 是一个数据结构, 可以理解为多维数组, 用于表示 neuron network 中的所有数据 (输入, 输出, 参数等). 类似 <code>NumPy</code> 中的 <code>ndarray</code>, 但支持 GPU 加速和自动微分.</p>
<p>两个常见属性:</p>
<ul>
<li><code>shape</code> 表示维度结构, 每一层的大小</li>
<li><code>dtype</code> 表示数据类型, 如 <code>float32</code>, <code>int64</code></li>
</ul>
<p>创建张量:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br><span class="hljs-comment"># 创建张量</span><br>scalar = tf.constant(<span class="hljs-number">3.0</span>)                      <span class="hljs-comment"># 标量</span><br>vector = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])                <span class="hljs-comment"># 向量</span><br>matrix = tf.constant([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])         <span class="hljs-comment"># 矩阵</span><br>image_batch = tf.random.normal([<span class="hljs-number">32</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">3</span>]) <span class="hljs-comment"># 4维张量（图像批次）</span><br></code></pre></td></tr></table></figure>

<h2 id="Layer"><a href="#Layer" class="headerlink" title="Layer"></a>Layer</h2><p>Layer 是 neuron network 中的一个构建单元, 用于对输入张量进行特定变换, 如卷积, 全连接, 激活函数等.</p>
<p><img src="/../img/deep-learning-layer-example.png" srcset="/img/loading.gif" lazyload></p>
<p>常见 layer 如下.</p>
<h3 id="Flatten"><a href="#Flatten" class="headerlink" title="Flatten"></a>Flatten</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tf.keras.layers.Flatten(input_shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>))<br></code></pre></td></tr></table></figure>
<ul>
<li>将指定 shape 的输入展平为一维向量</li>
<li>例如输入: <code>(batch_size, 28, 28)</code> 的张量, 输出 <code>(batch_size, 784)</code> 张量</li>
</ul>
<h3 id="Dense"><a href="#Dense" class="headerlink" title="Dense"></a>Dense</h3><p>Dense layer, 全连接层, 将输入的所有元素与指定个数的 neuron 通过权重连接, 并应用指定激活函数, 实现高维映射或降维:</p>
<p><img src="/../img/deep-learning-dense-layer-example.png" srcset="/img/loading.gif" lazyload></p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>Output &#x3D; Activation(W \cdot Input + b)<br>\end{aligned}<br>}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tf.keras.layers.Dense(<span class="hljs-number">128</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>)<br></code></pre></td></tr></table></figure>
<ul>
<li>例如输入: <code>(batch_size, 784)</code> 张量, 输出 <code>(batch_size, 128)</code> 张量</li>
<li><code>128</code> 指定 neuron 的数量, 同样也是指定输出的数量</li>
</ul>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>改 Layer 并不包含 neuron, 而是随机丢弃 (置零) <code>x%</code> 的神经元输出, 防止过拟合:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tf.keras.layers.Dropout(rate=<span class="hljs-number">0.5</span>)<br></code></pre></td></tr></table></figure>

<p><img src="/../img/deep-learning-dropout-50-persent-example.png" srcset="/img/loading.gif" lazyload></p>
<p>丢弃一部分 neuron 能够让网路不依赖单个 neuron, 增强泛化能力.</p>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p>Batch Normalization, batchnorm, 用于 correct 训练过慢或者 unstable 的情况. 将 batch 输入缩放到一定范围, 一般进行标准化 (均值&#x3D;0, 方差&#x3D;1 的分布).</p>
<ul>
<li>均值为 <code>0</code>, 表示数据以 <code>0</code> 为中心分布</li>
<li>方差为 <code>1</code>, 表示数据间的尺度更小, 减少数值计算中的舍入误差</li>
</ul>
<p><img src="/../img/deep-learning-standard-distribution-example.png" srcset="/img/loading.gif" lazyload></p>
<p>Batchnorm layer 可以放在 network 中的任意位置, 如:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">layers.Dense(<span class="hljs-number">16</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>),<br>layers.BatchNormalization(),<br></code></pre></td></tr></table></figure>

<p>或:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">layers.Dense(<span class="hljs-number">16</span>),<br>layers.BatchNormalization(),<br>layers.Activation(<span class="hljs-string">&#x27;relu&#x27;</span>),<br></code></pre></td></tr></table></figure>

<p>如果放在第一层, 就相当于一个预处理器来缩放输入.</p>
<h3 id="Hidden"><a href="#Hidden" class="headerlink" title="Hidden"></a>Hidden</h3><p>Hidden layer 指 output layer 之前的所有 layer, 因为它们的输出我们不会直接看到.</p>
<h2 id="Activation-function"><a href="#Activation-function" class="headerlink" title="Activation function"></a>Activation function</h2><p>Activation function, 激活函数, 指非线性变换函数, 用于向网络引入非线性能力, 使其能够学习复杂的模式, 没有激活函数, 神经网络将退化为线性回归模型, 无法解决非线性问题 (应用到 layer 的输出上).</p>
<p><img src="/../img/deep-learning-fitting-nonlinear-relationship.png" srcset="/img/loading.gif" lazyload></p>
<p>因为无论堆叠多少线性层, 其整体还是线性变换: $W_1 * W_2 * … * W_n * X$.</p>
<p>Activation function 在每个层后添加非线性, 让网络能够拟合任意复杂函数.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">layers.Dense(units=<span class="hljs-number">8</span>),<br>layers.Activation(<span class="hljs-string">&#x27;relu&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>等价于:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">layers.Dense(units=<span class="hljs-number">8</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>常见的激活函数如下.</p>
<h3 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h3><p>数学表示为:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>\sigma(x) &#x3D; \frac{1}{1 + e^{-x}}<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>输出范围 $[0,1]$</li>
</ul>
<p><img src="/../img/deep-learning-sigmoid-example.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h3><p>数学表示为:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>tanh(x) &#x3D; \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>输出范围 <code>[-1, 1]</code></li>
</ul>
<p><img src="/../img/deep-learning-tanh-example.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="ReLU-Rectified-Linear-Unit"><a href="#ReLU-Rectified-Linear-Unit" class="headerlink" title="ReLU, Rectified Linear Unit"></a>ReLU, Rectified Linear Unit</h3><p>数学表示:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>ReLU(x) &#x3D; max(0, x)<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>输出范围 $[0, +\infty]$</li>
</ul>
<p><img src="/../img/deep-learning-rectified-linear-unit-example.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="LeakyReLU"><a href="#LeakyReLU" class="headerlink" title="LeakyReLU"></a>LeakyReLU</h3><p>数学表示:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>LeakyReLU(x) &#x3D; \begin{cases}<br>x, if\ x \ge 0 \newline~ \newline<br>ax, if\ x &lt; 0<br>\end{cases}<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>通常 $a &#x3D; 0.01$</li>
</ul>
<h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><p>数学表示:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>Softmax(x_1) &#x3D; \frac{e^{x_i}}{\sum_j e^{x_j}}<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>输出范围: $[0,1]$, 且输出之和为 $1$</li>
</ul>
<h2 id="Batch"><a href="#Batch" class="headerlink" title="Batch"></a>Batch</h2><p>Batch 指每次训练选取的 training data.</p>
<h2 id="Epoch"><a href="#Epoch" class="headerlink" title="Epoch"></a>Epoch</h2><p>Epoch, 训练轮次, 指整个训练数据集被模型完全遍历一次.</p>
<p>每次训练时, <code>X_train</code> 会被分为多个 batch, 比如 10 个, 此时每轮 epoch 都会完成 10 次迭代.</p>
<p>分为 batch 可以控制每次参数更新的样本量, 以及内存&#x2F;显存的占用.</p>
<h2 id="Linear-unit"><a href="#Linear-unit" class="headerlink" title="Linear unit"></a>Linear unit</h2><p>Linear unit 指没有应用 activation function 的一个 layer. Neuron network 中的最后一层是 linear layer 让任务变回 regression task.</p>
<h2 id="Gradient-descent"><a href="#Gradient-descent" class="headerlink" title="Gradient descent"></a>Gradient descent</h2><p>Gradient descent, 梯度下降, 是一种优化模型参数的算法, 通过迭代调整参数, 以最小化 loss function.</p>
<p>算法目标的数学表达: 找到使损失函数 $J(\theta)$ 最小的参数 $\theta$:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>\theta^* &#x3D; arg\ \underset{\theta}{min} J (\theta)<br>\end{aligned}<br>}<br>$$</p>
<p>数学原理:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>\theta_{t+1} &#x3D; \theta_t - \eta \cdot \Delta_{\theta} J (\theta_t)<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>$\eta$, 学习率, 用于控制步长</li>
<li>$\Delta_{\theta} J (\theta_t)$ 是当前参数处的梯度</li>
</ul>
<p>也就是沿梯度的反方向更新参数.</p>
<h2 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h2><p>Stochastic Gradient Descent, 随机梯度下降, 指每次随机选一个样本计算梯度:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>\theta_{t+1} &#x3D; \theta_t - \eta \cdot \Delta_{\theta} J (\theta_t; x_i, y_i)<br>\end{aligned}<br>}<br>$$</p>
<p>一般需要设计 learning rate 和 batch size.</p>
<h2 id="Forward-Propagation"><a href="#Forward-Propagation" class="headerlink" title="Forward Propagation"></a>Forward Propagation</h2><p>Forward Propagation, 前向传播, 指数据从输入层经过各层计算, 最终得到输出预测值的过程.</p>
<h2 id="Backward-Propagation"><a href="#Backward-Propagation" class="headerlink" title="Backward Propagation"></a>Backward Propagation</h2><p>Backward Propagation, 反向传播, 指通过链式法则 (求导) 计算损失函数对向后传播每个参数的梯度, 用于更新权重和偏置 (这个过程需要保存中间结果).</p>
<blockquote>
<p>为什么要求导</p>
</blockquote>
<p>调整参数一般用 Gradient Descent:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>\theta_{t+1} &#x3D; \theta_t - \eta \cdot \nabla_{\theta} J (\theta_t)<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>$\theta$ 就是这里的 <code>Weights</code></li>
<li>因此只需要计算 $\nabla_{\theta} J (\theta_t)$, 及梯度, 也就是 $\frac{\partial J}{\partial \theta_t}$</li>
</ul>
<p>如果损失函数是用 MAE 计算, 即:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>J(\theta_t) &#x3D; \frac{|y - y’|}{n} \newline~ \newline<br>y’ &#x3D; \theta_t y’’ + b \newline~ \newline<br>\frac{\partial J}{\partial \theta_t} &#x3D; \frac{\partial J}{\partial y’} * \frac{\partial y’}{\partial \theta_t}<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>$\frac{\partial J}{\partial y’} &#x3D; \frac{1}{n}$, $\frac{\partial y’}{\partial \theta_t} &#x3D; y’’$, 因此能计算出该梯度为 $\frac{1}{n} * y’’$</li>
</ul>
<p>再往前推, 算 $\frac{\partial J}{\partial \theta_{t-1}}$:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>J(\theta_{t-1}) &#x3D; \frac{|y_{true} - y’’|}{n} \newline~ \newline<br>y’’ &#x3D; \theta_{t-1} y’’’ + b \newline~ \newline<br>\frac{\partial J}{\partial \theta_{t-1}} &#x3D; \frac{\partial J}{\partial y’’} * \frac{\partial y’’}{\partial \theta_{t-1}}<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>可以算出梯度为: $\frac{1}{n} * y’’’$</li>
</ul>
<p>可以看出来, 这里梯度的计算只依赖上一层的输出, 因此只要保留中间输出即可 (添加了 activation function 也是一样的, 链式法则多一条即可).</p>
<h2 id="Chain-Rule"><a href="#Chain-Rule" class="headerlink" title="Chain Rule"></a>Chain Rule</h2><p>Chain Rule, 链式法则, 是微积分中的核心规则, 用于计算符合函数的导数.</p>
<p>例如, 对 $y &#x3D; sin(e^{x^2})$ 求导:</p>
<ul>
<li>$u &#x3D; x^2 \rightarrow v &#x3D; e^u \rightarrow y &#x3D; sin(v)$</li>
<li>$\frac{y}{x} &#x3D; \frac{y}{v} * \frac{v}{u} * \frac{u}{x}$</li>
<li>$\frac{y}{x} &#x3D; cos(e^{x^2}) \cdot e^{x^2} \cdot 2x$</li>
</ul>
<h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><p>Loss function 用于评判 <code>target&#39;s true value</code> 与 <code>model predicts value</code> 之间的差值. 而在 neuron network 中, 会利用该值来调整 <code>weights</code>.</p>
<h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><p>Optimizer 用于调整 <code>weights</code> 来减小 loss.</p>
<h2 id="Cross-Entropy"><a href="#Cross-Entropy" class="headerlink" title="Cross Entropy"></a>Cross Entropy</h2><p>Cross Entropy, 交叉熵, 用于衡量两个概率分布之间的差异. 用作分类问题中的 loss function (让熵更小).</p>
<p><img src="/../img/deep-learning-cross-entropy-accuracy-example.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>横坐标是 <code>accuracy</code></li>
<li>纵坐标是 <code>cross entropy</code> loss function 计算出的 loss</li>
<li>可以看出准确率越高, loss 越小</li>
</ul>
<p>对于二分类问题, 其 cross entropy 的数学表达式为:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>H(p, q) &#x3D; - \sum_{x} p(x) log q(x)<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>$p(x)$ 是真实概率分布 (或者正确标签)</li>
<li>$q(x)$ 是预测概率分布 (或者预测标签)</li>
<li>$H(p,q)$ 越大, 表示误差越大</li>
</ul>
<p>比如:</p>
<ul>
<li>完美预测:<ul>
<li>有 $q(x) &#x3D; p(x)$</li>
<li>如果有 $p&#x3D;[0,0,1]$, $q&#x3D;[0,0,1]$</li>
<li>此时: $H(p,q) &#x3D; -(0 log 0 + 0 log 0 + 1 * log 1) &#x3D; 0$</li>
</ul>
</li>
<li>预测不准确:<ul>
<li>有 $q(x) !&#x3D; p(x)$</li>
<li>如果有 $p&#x3D;[0,0,1]$, $q&#x3D;[0.1,0.1,0.8]$</li>
<li>此时: $H(p,q) \approx 0.223$</li>
<li>如果有 $p&#x3D;[0,0,1]$, $q&#x3D;[0.3,0.3,0.4]$</li>
<li>此时: $H(p,q) \approx 0.916$</li>
</ul>
</li>
</ul>
<h2 id="Accuracy"><a href="#Accuracy" class="headerlink" title="Accuracy"></a>Accuracy</h2><p>Accuracy 计算分类问题的准确率, 计算为:</p>
<figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">accuracy</span> <span class="hljs-operator">=</span> number_correct / total<br></code></pre></td></tr></table></figure>
<ul>
<li>正确预测的数量与总预测次数之比</li>
</ul>
<h1 id="Keras-接口使用"><a href="#Keras-接口使用" class="headerlink" title="Keras 接口使用"></a>Keras 接口使用</h1><h2 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">mnist = tf.keras.datasets.mnist<br><br>(x_train, y_train), (x_test, y_test) = mnist.load_data()<br>x_train, x_test = x_train / <span class="hljs-number">255.0</span>, x_test / <span class="hljs-number">255.0</span><br></code></pre></td></tr></table></figure>

<h2 id="定义一个模型"><a href="#定义一个模型" class="headerlink" title="定义一个模型"></a>定义一个模型</h2><p>以 <code>Sequential</code> 模型为例子.</p>
<p><code>Sequential</code> 是顺序模型, 用于构建线性堆叠神经网络, 是最简单的模型类型, 适用于 layers 按顺序依次连接的架构, 数据从第一层输入, 依次传递到最后一层输出.</p>
<p>但其不能定义多输入, 多输出, 以及层间共享或跳跃连接.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">model = tf.keras.models.Sequential([<br>  tf.keras.layers.Flatten(input_shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>)),<br>  tf.keras.layers.Dense(<span class="hljs-number">128</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>),<br>  tf.keras.layers.Dropout(<span class="hljs-number">0.2</span>),<br>  tf.keras.layers.Dense(<span class="hljs-number">10</span>)<br>])<br></code></pre></td></tr></table></figure>

<p>获取模型的 <code>weight</code> 和 <code>bias</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">w, b = model.weights<br></code></pre></td></tr></table></figure>

<p>可以看到, 此时 <code>weights</code> 的设置是随机的.</p>
<p>Training 的过程就是调整 <code>weights</code>, 从而能将 <code>features</code> 计算得到 <code>target</code>.</p>
<h2 id="添加-loss-和-optimizer"><a href="#添加-loss-和-optimizer" class="headerlink" title="添加 loss 和 optimizer"></a>添加 loss 和 optimizer</h2><p>用 <code>compile</code> 方法:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">model.<span class="hljs-built_in">compile</span>(<br>    optimizer=<span class="hljs-string">&quot;adam&quot;</span>,<br>    loss=<span class="hljs-string">&quot;mae&quot;</span>,<br>)<br></code></pre></td></tr></table></figure>

<h2 id="拟合模型"><a href="#拟合模型" class="headerlink" title="拟合模型"></a>拟合模型</h2><p>用 <code>fit</code> 方法:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">history = model.fit(<br>    X_train, y_train,<br>    validation_data=(X_valid, y_valid),<br>    batch_size=<span class="hljs-number">256</span>,<br>    epochs=<span class="hljs-number">10</span>,<br>)<br></code></pre></td></tr></table></figure>

<h2 id="处理-binary-classification"><a href="#处理-binary-classification" class="headerlink" title="处理 binary classification"></a>处理 binary classification</h2><p>Deep learning 处理 classification 问题, 与处理 regression 问题主要的区别在于 loss function 的计算以及输出值的范围.</p>
<p>Binary classification 指, 将输入数据分成两个互斥的类别, 通常是:</p>
<ul>
<li>类别标签: 0&#x2F;1, 是&#x2F;否</li>
<li>概率值: 样本属于某一类的概率</li>
</ul>
<p>这里用 cross entropy 作为 loss function.</p>
<p>用 sigmoid function 映射概率分布. 设置 threshold probability, 如 <code>0.5</code>, 当概率值低于 <code>0.5</code>, 则输出 <code>label 0</code>, 高于 <code>0.5</code> 则输出 <code>label 1</code>.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Python/" class="category-chain-item">Python</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>TensorFlow-基本使用</div>
      <div>http://example.com/2025/07/12/TensorFlow-基本使用/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Jie</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年7月12日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/07/14/Python-matplotlib-%E5%BA%93/" title="Python-matplotlib-库">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Python-matplotlib-库</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/07/11/Deep-Learning-%E5%85%A5%E9%97%A8/" title="Deep-Learning-入门">
                        <span class="hidden-mobile">Deep-Learning-入门</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'zKurisu/comments-utterances');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Jie</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Orkarin</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
