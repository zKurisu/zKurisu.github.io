

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/wallhaven-j5kjgy_1920x1080.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Jie">
  <meta name="keywords" content="">
  
    <meta name="description" content="B 站王树森公开课 介绍Recommender system, 推荐系统, 是一种信息过滤技术, 用于预测用户对物品 (如商品, 电影, 新闻) 的偏好. 相关概念ExposureExposure, 曝光, 指内容或物品被展示给用户的次数. 比如某个物品 (如商品, 视频, 广告), 出现在用户的可视区域 (如 APP 首页, 搜索结果列表), 即完成一次曝光. Exposure 决定了用户是否看">
<meta property="og:type" content="article">
<meta property="og:title" content="Recommender-system-基础">
<meta property="og:url" content="http://example.com/2025/08/20/Recommender-system-%E5%9F%BA%E7%A1%80/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="B 站王树森公开课 介绍Recommender system, 推荐系统, 是一种信息过滤技术, 用于预测用户对物品 (如商品, 电影, 新闻) 的偏好. 相关概念ExposureExposure, 曝光, 指内容或物品被展示给用户的次数. 比如某个物品 (如商品, 视频, 广告), 出现在用户的可视区域 (如 APP 首页, 搜索结果列表), 即完成一次曝光. Exposure 决定了用户是否看">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/recommender-system-buckets-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-hold-out-method-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-top-k-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-click-and-read-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-item-expose-flow.png">
<meta property="og:image" content="http://example.com/img/recommender-system-some-rate-for-consumers.png">
<meta property="og:image" content="http://example.com/img/recommender-system-test-algorithm.png">
<meta property="og:image" content="http://example.com/img/recommender-system-linkage-structure.png">
<meta property="og:image" content="http://example.com/img/recommender-system-recall-process.png">
<meta property="og:image" content="http://example.com/img/recommender-system-ordering-process.png">
<meta property="og:image" content="http://example.com/img/recommender-system-reordering-items.png">
<meta property="og:image" content="http://example.com/img/recommender-system-ordering-structure-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-ab-testing-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-multilayer-experiment.png">
<meta property="og:image" content="http://example.com/img/recommender-system-reverse-bucket-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-itemcf-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-calculate-interesting-score-for-item.png">
<meta property="og:image" content="http://example.com/img/recommender-system-item-with-high-similarity.png">
<meta property="og:image" content="http://example.com/img/recommender-system-item-with-low-similarity.png">
<meta property="og:image" content="http://example.com/img/recommender-system-user-item-index-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-item-item-index-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-online-recall-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-itemCF-with-bad-people.png">
<meta property="og:image" content="http://example.com/img/recommender-system-how-usercf-works.png">
<meta property="og:image" content="http://example.com/img/recommender-system-two-users-does-not-sim.png">
<meta property="og:image" content="http://example.com/img/recommender-system-two-similar-user.png">
<meta property="og:image" content="http://example.com/img/recommender-system-item-with-high-population.png">
<meta property="og:image" content="http://example.com/img/recommender-system-usercf-user-item-index.png">
<meta property="og:image" content="http://example.com/img/recommender-system-usercf-user-user-index.png">
<meta property="og:image" content="http://example.com/img/recommender-system-usercf-process.png">
<meta property="og:image" content="http://example.com/img/recommender-system-embedding-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-good-embedding-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-embedding-calculation-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-why-named-matrix-completion.png">
<meta property="og:image" content="http://example.com/img/recommender-system-matrix-completion-model-structure.png">
<meta property="og:image" content="http://example.com/img/recommender-system-basic-idea-for-matrix-completion.png">
<meta property="og:image" content="http://example.com/img/recommender-system-partition-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-two-tower-deal-user.png">
<meta property="og:image" content="http://example.com/img/recommender-system-two-tower-deal-item.png">
<meta property="og:image" content="http://example.com/img/recommender-system-two-tower-structure.png">
<meta property="og:image" content="http://example.com/img/recommender-system-pairwise-structure-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-listwise-structure.png">
<meta property="og:image" content="http://example.com/img/recommender-system-how-to-chose-negative-sample.png">
<meta property="og:image" content="http://example.com/img/recommender-system-in-batch-negative-sample-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-can-not-used-in-recall.png">
<meta property="og:image" content="http://example.com/img/recommender-system-after-train-two-tower.png">
<meta property="og:image" content="http://example.com/img/recommender-system-store-item-vector-in-database.png">
<meta property="og:image" content="http://example.com/img/recommender-system-user-tower-recall.png">
<meta property="og:image" content="http://example.com/img/recommender-system-why-two-increase-model.png">
<meta property="og:image" content="http://example.com/img/recommender-system-loss-for-listwise.png">
<meta property="og:image" content="http://example.com/img/recommender-system-item-tower-data-augmentation.png">
<meta property="og:image" content="http://example.com/img/recommender-system-self-supervised-learning-similarity.png">
<meta property="og:image" content="http://example.com/img/recommender-system-related-mask-features.png">
<meta property="og:image" content="http://example.com/img/recommender-system-cal-two-related-features.png">
<meta property="og:image" content="http://example.com/img/recommender-system-how-to-do-mask-related.png">
<meta property="og:image" content="http://example.com/img/recommender-system-learn-with-self-supervised.png">
<meta property="og:image" content="http://example.com/img/recommender-system-item-as-path-example.png">
<meta property="og:image" content="http://example.com/img/deep-retrivel-get-path-example.png">
<meta property="og:image" content="http://example.com/img/recommender-system-beam-search-with-size-1.png">
<meta property="og:image" content="http://example.com/img/recommender-system-beam-size-4-example1.png">
<meta property="og:image" content="http://example.com/img/recommender-system-how-item-to-path.png">
<meta property="og:image" content="http://example.com/img/recommender-system-deep-retrievel-train-process.png">
<meta property="article:published_time" content="2025-08-20T09:35:07.000Z">
<meta property="article:modified_time" content="2025-09-11T03:04:54.701Z">
<meta property="article:author" content="Jie">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/recommender-system-buckets-example.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Recommender-system-基础 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  



  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Jie</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/SteinsGate_all.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Recommender-system-基础"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-08-20 17:35" pubdate>
          2025年8月20日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          21k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          174 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Recommender-system-基础</h1>
            
            
              <div class="markdown-body">
                
                <p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1HZ421U77y/?spm_id_from=333.337.search-card.all.click&vd_source=bc8ddbb1a08707dc809c3fd9bb85290d">B 站王树森公开课</a></p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Recommender system, 推荐系统, 是一种信息过滤技术, 用于预测用户对物品 (如商品, 电影, 新闻) 的偏好.</p>
<h1 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h1><h2 id="Exposure"><a href="#Exposure" class="headerlink" title="Exposure"></a>Exposure</h2><p>Exposure, 曝光, 指内容或物品被展示给用户的次数.</p>
<p>比如某个物品 (如商品, 视频, 广告), 出现在用户的可视区域 (如 APP 首页, 搜索结果列表), 即完成一次曝光.</p>
<p>Exposure 决定了用户是否看到某物品. 也会直接影响广告主的投放效果以及平台的收入 (某些计费规则依赖曝光量).</p>
<h2 id="CTR"><a href="#CTR" class="headerlink" title="CTR"></a>CTR</h2><p>CTR, Click-Through Rate, 点击通过率, 表示用户看到某个推荐内容后实际点击的概率:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>CTR &#x3D; \frac{点击次数}{曝光次数} \times 100 \%<br>\end{aligned}<br>}<br>$$</p>
<p>CTR 越高, 说明推荐内容越符合用户兴趣.</p>
<h2 id="Log"><a href="#Log" class="headerlink" title="Log"></a>Log</h2><p>推荐系统中的 Log 用于记录用户和系统交互的完整轨迹, 比如:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;user_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;u123&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;item_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;i456&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;timestamp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2023-10-01 14:00:00.123&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;position&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;page_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;homepage&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;device&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ios&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;network&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;wifi&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;session_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;s789&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;ranking_score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.87</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>
<ul>
<li><code>user_id</code>, 标识用户唯一身份, 用于用户行为分析, 个性化推荐</li>
<li><code>item_id</code>, 表示被曝光的物品 (商品&#x2F;视频等), 用于物品热度统计, CTR 预估</li>
<li><code>timestamp</code>, 精确的事件时间, 用于行为序列分析和时效判断 (比如节日效应)</li>
<li><code>position</code>, 物品在列表中展示的位置 (比如排第 3 个), 用于位置偏差修正 (首页的曝光点击率更高)</li>
<li><code>page_type</code>, 曝光发生的页面场景 (首页&#x2F;搜索页等),用于场景化推荐策略 (不同页面类别不同)</li>
<li><code>device/network</code>, 指用户设备和网络环境, 用于性能优化, 适配策略等</li>
<li><code>session_id</code>, 用户单次会话标识, 用于会话内行为分析</li>
<li><code>ranking_score</code>, 是模型对该物品的预测分数, 用于曝光偏差分析</li>
</ul>
<h2 id="HitRate-K-指标"><a href="#HitRate-K-指标" class="headerlink" title="HitRate@K 指标"></a>HitRate@K 指标</h2><p><code>HitRate@K</code> 指标是推荐系统中用于评估 <code>Top-K</code> 推荐列表质量的常用指标, 衡量推荐结果是否 “Hit” 用户的真实兴趣.</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>HitRate@K &#x3D; \frac{Number\ of\ Hits@K}{Total\ Users} \times 100\%<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li><code>Hit@K</code>, 指当前推荐列表中的前 K 个物品中如果有一件用户实际点击的物品, 则计 1 次数</li>
<li><code>Total Users</code> 是测试的用户总数</li>
</ul>
<p>比如向 100 个用户推荐 <code>Top-5</code> 列表, 其中 30 个用户的推荐列表中至少包含一件用户实际点击的物品, 则:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>HitRate@5 &#x3D; \frac{30}{100} \times 100\% &#x3D; 30\%<br>\end{aligned}<br>}<br>$$</p>
<p>该指标只关注是否 “Hit”, 而非物品的排名. 通常 <code>K</code> 越大, <code>HitRate@K</code> 越高.</p>
<h2 id="Recall-channel"><a href="#Recall-channel" class="headerlink" title="Recall channel"></a>Recall channel</h2><p>Recall channel, 召回通道, 是多路召回策略的具体实现, 每个通道代表一种独立的召回方法, 用于从数据库中筛选出部分候选集合.</p>
<p>使用多样化召回策略能够覆盖用户的潜在兴趣:</p>
<ul>
<li>比如不同通道筛选不同维度 (如历史行为, 热门趋势等)</li>
<li>对新用户, 新物品的冷启动处理, 利用特定的通道取得</li>
</ul>
<h2 id="MMR"><a href="#MMR" class="headerlink" title="MMR"></a>MMR</h2><p>MMR, Maximal Marginal Relevance, </p>
<h2 id="DPP"><a href="#DPP" class="headerlink" title="DPP"></a>DPP</h2><p>DPP, Determinantal Point Process, </p>
<h2 id="随机分桶"><a href="#随机分桶" class="headerlink" title="随机分桶"></a>随机分桶</h2><p>随机分桶, Random Bucketing, 是数据处理的常见策略, 其核心思想是: 将数据或对象随机分配到有限数量的桶 (buckets) 中, 每个桶代表一个分组或分区. 分配过程尽量保证每个桶被选中的概率是相同或可控的.</p>
<p>比如在 A&#x2F;B 测试中, 有 3 个 buckets:</p>
<ul>
<li>Bucket 0: 对照组 (旧功能)</li>
<li>Bucket 1: 实验组 (新功能 A)</li>
<li>Bucket 2: 实验组 (新功能 B)</li>
</ul>
<p>将一组用户随机分配到一个桶中测试效果.</p>
<p>另一个示例, 比如有 $n$ 个用户, 分为 $b$ 个桶, 每个桶分配 $\frac{n}{b}$ 个用户:</p>
<p><img src="/../img/recommender-system-buckets-example.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="北极星指标"><a href="#北极星指标" class="headerlink" title="北极星指标"></a>北极星指标</h2><p>北极星指标, North Star Metric, 是衡量推荐系统长期成功与否的核心指标, 正如其名, 像北极星一样指引产品发展方向.</p>
<p>如果与其他指标冲突 (如 CTR 短期上升但用户留存下降), 应以北极星指标为准.</p>
<p>常用的北极星指标有 3 类:</p>
<ol>
<li><p>用户规模指标, 可以衡量推荐系统的粘性:<br> a. DAU, Daily Active Users, 1 天内至少使用一次推荐功能的用户<br> b. MAU, Monthly Active Users, 30 天内至少使用一次推荐功能的用户</p>
</li>
<li><p>消费指标:<br> a. 人均使用时长, 用户通过推荐系统查阅物品的总时长的平均值. 用于衡量推荐内容的吸引力 (如果高 CTR 但低时长, 可能暗示题目显眼但内容低质)<br> b. 人均阅读物品数量, 用户通过推荐系统查看的物品量的平均值</p>
</li>
</ol>
<h2 id="Holdout-Method"><a href="#Holdout-Method" class="headerlink" title="Holdout Method"></a>Holdout Method</h2><p>Holdout method, 保留机制, 是机器学习中一种经典的数据划分和评估方法, 其核心思想是: 从原始数据集中按一定比例划分出一部分数据作为 holdout set, 用于模型评估, 剩余数据用于训练.</p>
<p>比如:</p>
<p><img src="/../img/recommender-system-hold-out-method-example.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="Cosine-similarity"><a href="#Cosine-similarity" class="headerlink" title="Cosine similarity"></a>Cosine similarity</h2><p>Cosine similarity, 余弦相似度, 通过计算两个向量在空间中的夹角余弦值, 来衡量他们在方向上的相似度, 而不考虑向量长度. 值越接近 <code>1</code>, 表示方向越相似, 越接近 <code>0</code>, 表示越不相似.</p>
<p>数学定义, 假设有两个向量:</p>
<ul>
<li>向量 $A$: $\overline{A} &#x3D; (A_1, A_2, …, A_n)$</li>
<li>向量 $B$: $\overline{B} &#x3D; (B_1, B_2, …, B_n)$</li>
</ul>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>cosine_similarity(A,B) &#x3D; \frac{\overline{A} \cdot \overline{B}}{\Vert \overline{A} \Vert \cdot \Vert \overline{B} \Vert}<br>\end{aligned}<br>}<br>$$</p>
<h2 id="正负样本"><a href="#正负样本" class="headerlink" title="正负样本"></a>正负样本</h2><p>正样本, Positive samples, 指我们感兴趣的目标, 含感兴趣特征&#x2F;模式的样本.</p>
<p>负样本, Negative samples, 指不包含目标特征, 代表背景, 正常情况或非目标类别的样本.</p>
<p>在实际应用中, 通常正样本比负样本少得多.</p>
<p>比如在垃圾邮件检测中:</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">正样本: 垃圾邮件</span><br><span class="hljs-section">负样本: 正常邮件</span><br></code></pre></td></tr></table></figure>

<p>在人脸识别中:</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">正样本: 包含人脸的图像区域</span><br><span class="hljs-section">负样本: 不包含人脸的图像区域</span><br></code></pre></td></tr></table></figure>

<p>模型训练中, 需要正负样本共同帮助模型区分不同类别的界限, 以提升模型的泛化能力.</p>
<h2 id="Long-Tail-items"><a href="#Long-Tail-items" class="headerlink" title="Long-Tail items"></a>Long-Tail items</h2><p>Long-Tail items (长尾物品), 指曝光量低, 点击量少, 销量小的物品, 它们通常占据了物品库的绝大多数, 单个物品的流行度远低于头部热门物品.</p>
<h2 id="常见特征工程术语"><a href="#常见特征工程术语" class="headerlink" title="常见特征工程术语"></a>常见特征工程术语</h2><h3 id="User-Sparse-Features"><a href="#User-Sparse-Features" class="headerlink" title="User Sparse Features"></a>User Sparse Features</h3><p>User Sparse Features, 用户稀疏特征, 指离散的类别特征, 通常为低维, 高基数 (比如性别, 城市, 职业).</p>
<p>这种特征:</p>
<ul>
<li>取值有限</li>
<li>需要编码为整数索引</li>
<li>通过 Embedding 层转换为稠密向量</li>
</ul>
<p>比如:</p>
<ul>
<li>用户性别: <code>[&quot;男&quot;, &quot;女&quot;]</code> $\rightarrow$ <code>[0,1]</code></li>
<li>用户城市: <code>[&quot;北京&quot;, &quot;上海&quot;, &quot;深圳&quot;]</code> $\rightarrow$ <code>[0,1,2]</code></li>
<li>用户职业: <code>[&quot;学生&quot;, &quot;工程师&quot;, &quot;教师&quot;]</code> $\rightarrow$ <code>[0,1,2]</code></li>
</ul>
<h2 id="User-Array-Features"><a href="#User-Array-Features" class="headerlink" title="User Array Features"></a>User Array Features</h2><p>User Array Features, 多值离散特征, 表示用户有多个标签或行为.</p>
<p>对于这类特征:</p>
<ul>
<li>每个用户对应一个列表 (如兴趣标签, 历史行为)</li>
<li>需要处理为 <code>multi-hot encoding</code> 或聚合统计</li>
</ul>
<p>比如:</p>
<ul>
<li>用户兴趣标签: <code>[&quot;科技&quot;, &quot;体育&quot;, &quot;音乐&quot;]</code> $\rightarrow$ <code>[1,1,0]</code></li>
<li>用户最近点击的物品 ID 列表: <code>[&quot;item1&quot;, &quot;item2&quot;]</code> $\rightarrow$ <code>[0,1,1,0]</code> (假设物品库为 <code>[item1, item2, item3, item4]</code>)</li>
</ul>
<h3 id="Item-Sparse-Features"><a href="#Item-Sparse-Features" class="headerlink" title="Item Sparse Features"></a>Item Sparse Features</h3><p>Item Sparse Features, 物品稀疏特征, 指物品的离散类别属性, 描述物品的静态分类信息.</p>
<p>与用户稀疏特征类似:</p>
<ul>
<li>取值有限</li>
<li>需要编码为整数索引</li>
<li>通过 Embedding 层转换为稠密向量</li>
</ul>
<p>比如:</p>
<ul>
<li>物品类别: <code>[&quot;电子产品&quot;, &quot;服装&quot;, &quot;食品&quot;]</code> $\rightarrow$ <code>[0, 1, 2]</code></li>
<li>物品品牌: <code>[&quot;苹果&quot;, &quot;华为&quot;, &quot;小米&quot;]</code> $\rightarrow$ <code>[0, 1, 2]</code></li>
<li>物品价格区间: <code>[&quot;0-100&quot;, &quot;100-500&quot;, &quot;500+&quot;]</code> $\rightarrow$ <code>[0, 1, 2]</code></li>
</ul>
<h3 id="Item-Array-Features"><a href="#Item-Array-Features" class="headerlink" title="Item Array Features"></a>Item Array Features</h3><p>Item Array Features, 物品多值特征, 表示物品的多个关联标签或属性:</p>
<ul>
<li>每个物品对应一个列表, 如关键词, 适用人群</li>
<li>处理方式与 user array features 类似</li>
</ul>
<p>比如:</p>
<ul>
<li>物品关键词: <code>[&quot;轻薄&quot;, &quot;高性能&quot;, &quot;便捷&quot;]</code> $\rightarrow$ <code>[1, 1, 0]</code></li>
<li>物品适用场景: <code>[&quot;办公&quot;, &quot;游戏&quot;, &quot;学习&quot;]</code> $\rightarrow$ <code>[1, 0, 1]</code></li>
</ul>
<h3 id="Item-Embedding-Features"><a href="#Item-Embedding-Features" class="headerlink" title="Item Embedding Features"></a>Item Embedding Features</h3><p>Item Embedding Features, 物品嵌入特征, 指预训练的稠密向量, 表示物品的隐含语义 (如通过 <code>Word2Vec</code>, 矩阵分解生成).</p>
<ul>
<li>可以直接作为模型输入, 无需额外编码</li>
<li>通常需要通过其他模型预训练得到</li>
</ul>
<p>比如:</p>
<ul>
<li>电影嵌入向量: <code>[0.1, -0.2, 0.5, ...]</code> (维度由预训练模型决定)</li>
<li>商品潜入向量: 通过用户行为序列训练得到</li>
</ul>
<h3 id="User-Continual-Features"><a href="#User-Continual-Features" class="headerlink" title="User Continual Features"></a>User Continual Features</h3><p>User Continual Features, 用户连续特征, 是数值型特征, 描述用户的连续属性:</p>
<ul>
<li>需要标准化 (z-score) 或分桶 (年龄分段)</li>
<li>可以直接输入模型作为辅助特征</li>
</ul>
<p>比如:</p>
<ul>
<li>用户年龄: <code>25</code> (原始值) $\rightarrow$ 标准化为 <code>0.3</code></li>
<li>用户活跃度 (日均点击次数) $\rightarrow$ 分桶为 <code>[0-5:0, 5-10:1]</code> $\rightarrow$ 编码为 <code>1</code></li>
</ul>
<h3 id="Item-Continual-Features"><a href="#Item-Continual-Features" class="headerlink" title="Item Continual Features"></a>Item Continual Features</h3><p>Item Continual Features, 物品连续特征, 物品的数值型特征, 描述物品的物理或统计特性.</p>
<p>与 User Continual Features 类似:</p>
<ul>
<li>需要标准化 (z-score) 或分桶</li>
<li>可以直接输入模型作为辅助特征</li>
</ul>
<p>比如:</p>
<ul>
<li>物品价格: <code>299.0</code> $\rightarrow$ 标准化为 <code>-0.1</code></li>
<li>物品评分均值: <code>4.5</code> $\rightarrow$ 直接输入模型</li>
</ul>
<h2 id="ANN"><a href="#ANN" class="headerlink" title="ANN"></a>ANN</h2><p>ANN, Approximate Nearest Neighbor, 是一种从海量高维数据中快速查找 “近似” 最相似项的技术. 其核心思想是牺牲一些精度以加速检索:</p>
<ul>
<li>Exact NN, 精确最近邻, 能够 <code>100%</code> 找到最相似项, 但计算成本高 (<code>O(n)</code> 或更高)</li>
<li>ANN, 近似最近邻, 找到足够相似 (Top-K) 的项, 速度提升百千倍, 允许在毫秒级处理十亿级数据</li>
</ul>
<p>所有 ANN 算法都会预先对数据索引 (indexing), 以减少检索时的计算量.</p>
<h2 id="Semantic-ID"><a href="#Semantic-ID" class="headerlink" title="Semantic ID"></a>Semantic ID</h2><p>Semantic ID, 语义标识符, 是一种物品表示方法, 用一段短序列 (如 <code>[23, 45, 9]</code>) 来替代传统的随机, 无意义的 ID, 直接编码物品的语义信息.</p>
<p>比如:</p>
<ul>
<li>一个商品, 传统 ID 可能是 <code>item_10283475</code></li>
<li>其 Semantic ID 可能是 <code>[5, 12, 9]</code>:<ul>
<li><code>5</code> 可能代表类别是 “电子产品”</li>
<li><code>12</code> 可能代表品牌是 “苹果”</li>
<li><code>9</code> 可能代表型号是 “iPhone 15”</li>
</ul>
</li>
</ul>
<p>传统推荐模型的随机 Item ID 会有下面问题:</p>
<ul>
<li>冷启动问题: 新物品的 ID 从未出现过, 模型无法处理, 必须重新训练</li>
<li>泛化能力差: <code>item_10283475</code> 和 <code>item_10283476</code> 在模型看来是两个完全独立的实体, 即使它们可能是同品牌同类型的商品</li>
</ul>
<p>Semantic ID 的优势:</p>
<ol>
<li>极强的泛化性, 即使是一个从未见过的新商品, 只要通过 RQ-VAE 模型计算出它的 Semantic ID 是 <code>[5, 12, 9]</code>, 从而做出高质量推荐, 解决冷启动问题</li>
<li>压缩与效率, 用一个短的离散ID序列替代庞大的多模态嵌入向量, 极大节省了存储和传输开销, 同时更适合索引和检索</li>
</ol>
<h2 id="NDCG"><a href="#NDCG" class="headerlink" title="NDCG"></a>NDCG</h2><p>NDCG, Normalized Discounted Cumulative Gain, 归一化折损累计增益. 其用来衡量 “推荐系统不仅要包含相关物品, 而且相关物品的排序越靠前越好”.</p>
<p>NDCG 会对推荐列表中每个位置的物品打分, 并考虑其位置信息进行加权求和 (累计增益), 同时进行归一化.</p>
<ul>
<li>Gain, 指物品的相关性分数表示</li>
<li>Discount, 越排在后面的物品, 其贡献应该越小, 用 <code>log</code> 函数进行折扣</li>
<li>Cumulative, 把每个位置的折扣增益加起来</li>
</ul>
<p>一个简化的计算方式:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>DCG@K &#x3D; \sum_{i&#x3D;1}^K \frac{rel_i}{log_2(i+1)}<br>\end{aligned}<br>}<br>$$</p>
<p>还需要计算一个 <code>IDCG@K</code>, 其由用户真实感兴趣的物品排序后计算:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>IDCG@K &#x3D; \sum_{i&#x3D;1}^K \frac{rel_i}{log_2(i+1)}<br>\end{aligned}<br>}<br>$$</p>
<p>最后:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>NDCG@K &#x3D; \frac{DCG@K}{IDCG@K}<br>\end{aligned}<br>}<br>$$</p>
<h2 id="Cold-Start"><a href="#Cold-Start" class="headerlink" title="Cold Start"></a>Cold Start</h2><p>Cold start, 冷启动, 是推荐系统中的常见问题, 一般有 3 种类型:</p>
<ul>
<li>用户冷启动, 对于新用户, 系统没有该用户的历史行为数据 (比如点击, 购买, 浏览序列)</li>
<li>物品冷启动, 对于新物品, 系统没有该物品的历史交互数据或特征</li>
<li>特征冷启动, 某个特征 (比如用户的某个属性, 物品的某个标签) 在训练集中很少出现, 或者从未见过, 导致模型难以学习其表示</li>
</ul>
<h3 id="默认置-0-的处理逻辑"><a href="#默认置-0-的处理逻辑" class="headerlink" title="默认置 0 的处理逻辑"></a>默认置 0 的处理逻辑</h3><p>比如有一个特征 <code>item_category</code>, 已知的特征值如 <code>sports</code>, <code>tech</code> 这些字符串都可以被映射为数字 (通过 embedding 等).</p>
<p>如果出现了新类别, 比如 <code>new_category_xxx</code>, 这个类别没有在训练时见过, 没有对应的 embedding 或 ID 映射 (通常训练时的 embedding 层的 <code>embedding_num</code> 就是类别数量一一对应).</p>
<p>如果直接使用这个字符串会导致:</p>
<ul>
<li>无法查找 <code>embedding</code></li>
<li>input 必须是 <code>int</code> 时报错</li>
</ul>
<p>此时的一个安全处理是, 将任何位置字符串特征值, 替换为一个默认值, 通常为 0, 其可以表示:</p>
<ul>
<li>未知类别</li>
<li>默认的 embedding 向量</li>
</ul>
<p>示例代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_process_cold_start_feat</span>(<span class="hljs-params">feat</span>):<br>    processed_feat = &#123;&#125;<br>    <span class="hljs-keyword">for</span> feat_id, feat_value <span class="hljs-keyword">in</span> feat.items():<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(feat_value) == <span class="hljs-built_in">list</span>:<br>            value_list = []<br>            <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> feat_value:<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(v) == <span class="hljs-built_in">str</span>:<br>                    value_list.append(<span class="hljs-number">0</span>)<br>                <span class="hljs-keyword">else</span>:<br>                    value_list.append(v)<br>            processed_feat[feat_id] = value_list<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">type</span>(feat_value) == <span class="hljs-built_in">str</span>:<br>            processed_feat[feat_id] = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">else</span>:<br>            processed_feat[feat_id] = feat_value<br>    <span class="hljs-keyword">return</span> processed_feat<br></code></pre></td></tr></table></figure>

<h2 id="Token-type"><a href="#Token-type" class="headerlink" title="Token type"></a>Token type</h2><p>对于用户行为序列, 假设格式为:</p>
<figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs elm">[(user_id, item_id, user_feat, item_feat, action_<span class="hljs-keyword">type</span>, timestamp)]<br></code></pre></td></tr></table></figure>
<ul>
<li>序列中的每个元素是一个元组, 包含各类信息</li>
</ul>
<p><code>user_id</code> 和 <code>item_id</code> 通常需要用于查找 embedding, 而两者用不同的 embedding 层处理, 因此要做区分, 这也是需要 token type 的原因之一.</p>
<h2 id="常见-ID"><a href="#常见-ID" class="headerlink" title="常见 ID"></a>常见 ID</h2><h3 id="item-id"><a href="#item-id" class="headerlink" title="item_id"></a><code>item_id</code></h3><p><code>item_id</code> 指系统中 item (物品) 的唯一标识符, 比如:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">item_ids = [<span class="hljs-number">101</span>, <span class="hljs-number">102</span>, <span class="hljs-number">103</span>, <span class="hljs-number">104</span>]<br></code></pre></td></tr></table></figure>

<h3 id="creative-id"><a href="#creative-id" class="headerlink" title="creative_id"></a><code>creative_id</code></h3><p><code>creative_id</code> 通常指广告系统中的广告创意 (creative) 的唯一标识.</p>
<p>Creative 可以是:</p>
<ul>
<li>一张广告图片</li>
<li>一段广告视频</li>
<li>广告文案 + 图片组合</li>
</ul>
<p>比如:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">creative_ids = [<span class="hljs-number">2001</span>, <span class="hljs-number">2002</span>, <span class="hljs-number">2003</span>]<br></code></pre></td></tr></table></figure>

<h3 id="retrieval-id"><a href="#retrieval-id" class="headerlink" title="retrieval_id"></a><code>retrieval_id</code></h3><p><code>retrieval_id</code> 指候选 id, 指检索 (retrieval) 阶段从数据库中取出的一组ID, 可以是:</p>
<ul>
<li>候选 item id</li>
<li>候选 creative id</li>
</ul>
<p>比如:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">retrieval_ids = [<span class="hljs-number">3001</span>, <span class="hljs-number">3002</span>, <span class="hljs-number">3003</span>]<br></code></pre></td></tr></table></figure>

<h2 id="Embedding-queries"><a href="#Embedding-queries" class="headerlink" title="Embedding queries"></a>Embedding queries</h2><p>Embedding queries 指, 把 query (可能是文本, 用户行为, 物品等) 转化为 embedding vector, 然后进行相似度计算, 召回和排序等.</p>
<p>在推荐系统中, query 可以是 <code>用户 ID + 用户最近行为</code>, 将其通过 Transformer&#x2F;BERT 等模型编码为 embedding 向量之后, 再用于召回.</p>
<h1 id="一个示例"><a href="#一个示例" class="headerlink" title="一个示例"></a>一个示例</h1><p>Recommender system 会根据用户的点击, 点赞, 收藏, 转发, 评论等行为, 来推荐用户可能感兴趣的东西.</p>
<p><img src="/../img/recommender-system-top-k-example.png" srcset="/img/loading.gif" lazyload></p>
<p>系统把物品展示给用户称为 Exposure (曝光), 如果用户对该物品感兴趣并点击, 且停留了一段时间, 可以粗略判断用户真的感兴趣, 此时可以算作一次有效点击, 如果用户向下滑动并阅读到底, 更能说明用户对其感兴趣:</p>
<p><img src="/../img/recommender-system-click-and-read-example.png" srcset="/img/loading.gif" lazyload></p>
<p>如果随后还触发了点赞, 收藏, 转发, 评论等, 也能作为指标判断用户对那类物品感兴趣以及用户对推荐是否满意:</p>
<p><img src="/../img/recommender-system-item-expose-flow.png" srcset="/img/loading.gif" lazyload></p>
<p>一些短期消费指标, 用于衡量用户短期消费兴趣, 除此之外需增加多样性让用户长期活跃:</p>
<p><img src="/../img/recommender-system-some-rate-for-consumers.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>点击率越高, 说明推荐越精准 (有些用显眼的标题和封面来骗点击)</li>
</ul>
<h2 id="实验流程"><a href="#实验流程" class="headerlink" title="实验流程"></a>实验流程</h2><p>算法的测试流程为:</p>
<p><img src="/../img/recommender-system-test-algorithm.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="推荐系统的链路"><a href="#推荐系统的链路" class="headerlink" title="推荐系统的链路"></a>推荐系统的链路</h1><p>推荐系统的目标是从庞大的数据库中找出用户可能感兴趣的物品.</p>
<p>推荐系统工作在下面几个步骤:</p>
<p><img src="/../img/recommender-system-linkage-structure.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>召回, 从数据库中取出大量物品</li>
<li>粗排, 用规模较小的机器学习模型给这些物品打分, 按照分数做排序和截断, 保留分数最高的部分物品</li>
<li>精排, 用大规模的深度学习神经网络对物品进行打分, 此时分数反应用户的兴趣, 此时可以截断也可以不截断</li>
<li>重排, 此时会根据精排分数和多样性分数做随机抽样, 还需要把相似内容打散, 并插入广告和运营内容</li>
</ul>
<p>在实践中, 会同时使用多个召回通道, 常见策略包括: 协同过滤, 双塔模型, 关注的作者等等. 召回的示例如下:</p>
<p><img src="/../img/recommender-system-recall-process.png" srcset="/img/loading.gif" lazyload></p>
<p>接下来进行排序, 粗排能减少计算量, 精排更准确:</p>
<p><img src="/../img/recommender-system-ordering-process.png" srcset="/img/loading.gif" lazyload></p>
<p>重排主要考虑多样性以及对相似内容的打散, 重排的结果就是最终展示给用户的物品:</p>
<p><img src="/../img/recommender-system-reordering-items.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="粗排和精排模型"><a href="#粗排和精排模型" class="headerlink" title="粗排和精排模型"></a>粗排和精排模型</h2><p>粗排使用较小的机器学习模型, 精排使用较大的深度学习模型.</p>
<p>模型输入包含: 用户特征, 物品特征, 统计特征等.</p>
<p>模型输出是对各指标的预估值, 数值越大, 表示用户更可能感兴趣. 综合各指标, 可以得到排序分数, 这个分数决定物品是否展示给用户, 以及展示的顺序, 位置.</p>
<p><img src="/../img/recommender-system-ordering-structure-example.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="重排"><a href="#重排" class="headerlink" title="重排"></a>重排</h2><p>重排常用 MMR, DPP 等方法做多样性抽样, 一般用两个依据进行抽样:</p>
<ul>
<li>精排输出的分数</li>
<li>多样性</li>
</ul>
<p>之后会用规则打散相似的笔记, 并插入广告和运营推广内容.</p>
<h1 id="A-x2F-B-测试"><a href="#A-x2F-B-测试" class="headerlink" title="A&#x2F;B 测试"></a>A&#x2F;B 测试</h1><p>A&#x2F;B 测试是一种对比实验方法, 通过将用户随机分为两组, 分别采用不同版本的策略, 评估其对指标的影响.</p>
<p>一般分为实验组 (Group A) 和对照组 (Group B), 需要确保两组用户特征分布一致.</p>
<p>遵循单一变量原则, 仅改变一个变量 (如推荐算法), 其他条件 (如用户流量, 时间窗口) 保持相同.</p>
<p><img src="/../img/recommender-system-ab-testing-example.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="分层实验"><a href="#分层实验" class="headerlink" title="分层实验"></a>分层实验</h2><p>每个测试条目作为一层, 同层之间多组测试的用户互斥:</p>
<p><img src="/../img/recommender-system-multilayer-experiment.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="反转实验"><a href="#反转实验" class="headerlink" title="反转实验"></a>反转实验</h2><p>反转实验指, 保留一个小的反转同, 应用旧策略以长期观察:</p>
<p><img src="/../img/recommender-system-reverse-bucket-example.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="ItemCF-召回通道"><a href="#ItemCF-召回通道" class="headerlink" title="ItemCF 召回通道"></a>ItemCF 召回通道</h1><p>ItemCF (Item Collaborative Filtering), 基于物品的协同过滤, 是一种推荐算法, 通过分析物品间的相似性, 为用户推荐与其喜欢的物品相似的其他物品.</p>
<p>Collaborative Filtering, 协同过滤, 指相似的用户会有相似的喜好, 或者相似的物品会被相似的用户喜欢. 只要分两大类:</p>
<ul>
<li>UserCF, 找到与你类似的用户, 推荐他们喜欢的, 但你还没接触过的物品</li>
<li>ItemCF, 找到与你喜欢的物品类似的其他物品并推荐</li>
</ul>
<p>一个 ItemCF 的示例:</p>
<p><img src="/../img/recommender-system-itemcf-example.png" srcset="/img/loading.gif" lazyload></p>
<p>预估用户对候选物品兴趣的示例:</p>
<ul>
<li>假如有一组用户历史物品数据, 通过点赞, 收藏等指标计算用户对物品兴趣的分数</li>
<li>计算个历史物品与候选物品的相似度信息</li>
<li>通过 $\sum_j like(user,item_j) \times sim(item_j, item)$ 求得预估值</li>
</ul>
<p><img src="/../img/recommender-system-calculate-interesting-score-for-item.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="物品相似度计算方法"><a href="#物品相似度计算方法" class="headerlink" title="物品相似度计算方法"></a>物品相似度计算方法</h2><p>如果物品的受众重合度越高, 两个物品越相似. 比如:</p>
<ul>
<li>喜欢 “宝可梦” 和 “洛克王国” 的玩家重合度很高</li>
<li>可以认为 “宝可梦” 和 “洛克王国” 相似</li>
</ul>
<p><img src="/../img/recommender-system-item-with-high-similarity.png" srcset="/img/loading.gif" lazyload></p>
<p>如果受众重合度低, 则说明不相似:</p>
<p><img src="/../img/recommender-system-item-with-low-similarity.png" srcset="/img/loading.gif" lazyload></p>
<p>一个简单的计算公式:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>sim(i_1, i_2) &#x3D; \frac{|v|}{\sqrt{|w_1| \cdot |w_2|}}<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>$w_1$ 是喜欢物品 $i_1$ 的用户集合</li>
<li>$w_2$ 是喜欢物品 $i_2$ 的用户集合</li>
<li>$v&#x3D;w_1 \cap w_2$ 是用户交集</li>
</ul>
<p>如果考虑用户喜欢物品的程度, 则公式变更为:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>sim(i_1, i_2) &#x3D; \frac{\sum_{v \in V} like(v, i_1) \cdot like (v, i_2)}{\sqrt{\sum_{u_1 \in w_1} like^2(u_1, i_1)} \cdot \sqrt{\sum_{u_2 \in w_2} like^2(u_2, i_2)}}<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>该公式也称 cosine similarity (余弦相似度)</li>
</ul>
<h2 id="ItemCF-召回的完整流程"><a href="#ItemCF-召回的完整流程" class="headerlink" title="ItemCF 召回的完整流程"></a>ItemCF 召回的完整流程</h2><h3 id="离线计算"><a href="#离线计算" class="headerlink" title="离线计算"></a>离线计算</h3><p>先做离线计算, 需要建立两组索引:</p>
<ul>
<li>$用户 \rightarrow 物品$ 索引</li>
</ul>
<p>需要记录每个用户最近点击, 交互过的物品 ID. 给定任意物品 ID, 可以找到他近期感兴趣的物品列表</p>
<p><img src="/../img/recommender-system-user-item-index-example.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>$物品 \rightarrow 物品$ 索引</li>
</ul>
<p>计算物品间两两相似度, 对于每个物品, 索引它最相似的 k 个物品. 给定任意物品 ID, 可以快速找到它最相似的 k 个物品.</p>
<p><img src="/../img/recommender-system-item-item-index-example.png" srcset="/img/loading.gif" lazyload></p>
<p>此时的计算量较大, 但能够减小线上计算量.</p>
<h3 id="线上召回"><a href="#线上召回" class="headerlink" title="线上召回"></a>线上召回</h3><p>上线后一个用户使用推荐系统时, 背后分 4 步:</p>
<ol>
<li>用用户 ID, 通过 $用户 \rightarrow 物品$ 索引, 找到用户近期感兴趣的物品列表 (<code>last-n</code>)</li>
<li>对于 <code>last-n</code> 列表中的每个物品, 通过 $物品 \rightarrow 物品$ 的索引, 找到 <code>top-k</code> 相似物品</li>
<li>对于检索的相似物品 (最多有 $nk$ 个), 用公式预估用户对物品的兴趣分数</li>
<li>返回分数最高的 100 个物品, 作为推荐结果</li>
</ol>
<p>比如:</p>
<ol>
<li>记录用户最近感兴趣的 $n&#x3D;200$ 个物品</li>
<li>取回每个物品最相似的 $k&#x3D;10$ 个物品</li>
<li>给取回的 $nk&#x3D;2000$ 个物品打分 (用户对物品的兴趣程度)</li>
<li>返回分数最高的 100 个物品最为 <code>ItemCF</code> 通道的输出</li>
</ol>
<p><img src="/../img/recommender-system-online-recall-example.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="Swing-召回通道"><a href="#Swing-召回通道" class="headerlink" title="Swing 召回通道"></a>Swing 召回通道</h1><p>Swing 是 ItemCF 的一种变体, 与 ItemCF 唯一的区别是对相似度的定义不同.</p>
<p>在 ItemCF 中, 物品的相似度定义为: 如果喜欢 $i_1$, $i_2$ 的用户有很大的重叠, 那么 $i_1$ 与 $i_2$ 相似.</p>
<p>ItemCF 会做这样的假设: 如果用户喜欢物品 $i_1$, 且物品 $i_1$ 与 $i_2$ 相似, 那么用户很可能喜欢物品 $i_2$.</p>
<p>但如果 ItemCF 的用户来自一个小圈子, 用户不够广泛和多样, 可能会让一些不相似的物品被误以为相似:</p>
<p><img src="/../img/recommender-system-itemCF-with-bad-people.png" srcset="/img/loading.gif" lazyload></p>
<p>而 Swing 则是给用户设置权重, 解决小圈子问题 (为了让测试用户更加多样广泛).</p>
<p>在 Swing 模型中:</p>
<ul>
<li>用户 $u_1$ 喜欢的物品记作集合 $J_1$</li>
<li>用户 $u_2$ 喜欢的物品记作集合 $J_2$</li>
<li>定义两个用户的重合度为: $overlap(u_1,u_2) &#x3D; |J_1 \cap J_2|$</li>
<li>用户 $u_1$ 和 $u_2$ 的重合度高, 则他们可能来自一个小圈子, 要降低其权重</li>
<li>喜欢物品 $i_1$ 的用户记作集合 $w_1$</li>
<li>喜欢物品 $i_2$ 的用户记作集合 $w_2$</li>
<li>定义交集 $v &#x3D; w_1 \cap w_2$</li>
<li>两个物品的相似度:</li>
</ul>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>sim(i_1, i_2) &#x3D; \sum_{u_1 \in v} \sum_{u_2 \in V} \frac{1}{\alpha + overlap(u_1,u_2)}<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>$\alpha$ 是可调整的参数</li>
</ul>
<h1 id="UserCF-召回通道"><a href="#UserCF-召回通道" class="headerlink" title="UserCF 召回通道"></a>UserCF 召回通道</h1><p>UserCF (User Collaborative Filtering), 基于用户的协同过滤, 其计算用户间的相似度用于推荐.</p>
<p>一个用户的点击, 收藏, 点赞, 转发会体现出其兴趣爱好, 而系统中存在许多与其兴趣类似的用户.</p>
<p>如果某个类似的用户对某物品点赞, 转发, 而一个用户如果没有看过这个物品, 那么推荐系统则有可能会推荐该物品.</p>
<p>每个用户都有一个列表, 记录了其点击, 点赞, 收藏, 转发的物品的 id, 对比两个用户的列表, 就能得知重合率, 重合越多说明两个用户越相似.</p>
<p>也可以通过对比用户关注的的作者列表得到是否相似.</p>
<p>在用 UserCF 做推荐之前, 需要先离线计算用户之间的相似度:</p>
<p><img src="/../img/recommender-system-how-usercf-works.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>similarity 数值越大表示越相似</li>
<li>要接受推荐的用户的兴趣值通过 $\sum sim \cdot like$ 计算</li>
<li>假设有 2000 个候选物品, 可以分别计算出兴趣值后排序, 取前 100 的进行推荐</li>
</ul>
<p>用户的相似度是用户之间相近兴趣点的度量:</p>
<ul>
<li>两个用户不相似, 指喜欢的物品没有重合</li>
</ul>
<p><img src="/../img/recommender-system-two-users-does-not-sim.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>两个用户相似, 指喜欢的物品有重合</li>
</ul>
<p><img src="/../img/recommender-system-two-similar-user.png" srcset="/img/loading.gif" lazyload></p>
<p>具体计算如下:</p>
<ul>
<li>用户 $u_1$ 喜欢的物品记作集合 $J_1$</li>
<li>用户 $u_2$ 喜欢的物品记作集合 $J_2$</li>
<li>定义交集 $I &#x3D; J_1 \cap J_2$, 包含两个用户共同喜欢的物品</li>
<li>计算相似度, 结果介于 $0~1$, 越接近 $1$ 说明越相似:</li>
</ul>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>sim(u_1, u_2) &#x3D; \frac{|I|}{\sqrt{|J_1| \cdot |J_2|}}<br>\end{aligned}<br>}<br>$$</p>
<p>上述公式还需考虑物品的权重, 热门的物品两个用户都看过的概率很大, 越热门的物品, 越不能反应用户独特的兴趣, 需要降低其权重; 重合的物品越冷门, 越能反应用户的兴趣:</p>
<p><img src="/../img/recommender-system-item-with-high-population.png" srcset="/img/loading.gif" lazyload></p>
<p>若考虑物品权重, 但不区分冷门和热门, 可以把上述公式改写为:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>sim(u_1, u_2) &#x3D; \frac{\sum_{l \in I} 1}{\sqrt{|J_1| \cdot |J_2|}}<br>\end{aligned}<br>}<br>$$<br>(权重都是 $1$ 说明不区分)</p>
<p>考虑热门程度, 公式应该改写为:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>sim(u_1, u_2) &#x3D; \frac{\sum_{l \in I} \frac{1}{\log(1 + n_l)}}{\sqrt{|J_1| \cdot |J_2|}}<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>$n_l$ 是喜欢物品 $l$ 的用户数量, 反映其热门程度. 越热门会让分子越小</li>
</ul>
<h2 id="UserCF-的召回流程"><a href="#UserCF-的召回流程" class="headerlink" title="UserCF 的召回流程"></a>UserCF 的召回流程</h2><p>先做离线计算, 建立两组索引:</p>
<ul>
<li>$用户 \rightarrow 物品$ 的索引, 记录每个用户最近点击, 交互过的物品 ID. 若给定任意用户 ID, 可以找到他近期感兴趣的物品列表</li>
</ul>
<p><img src="/../img/recommender-system-usercf-user-item-index.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>$用户 \rightarrow 用户$ 的索引, 索引与他最相似的 $k$ 个用户. 若给定任意用户 ID, 则可以快速找到他最相似的 $k$ 个用户</li>
</ul>
<p><img src="/../img/recommender-system-usercf-user-user-index.png" srcset="/img/loading.gif" lazyload></p>
<p>然后做线上召回:</p>
<ol>
<li>一个用户在使用系统, 通过用户 ID, 检索其 $用户 \rightarrow 用户$ 索引, 找到 <code>top-k</code> 相似用户</li>
<li>对于每个 <code>top-k</code> 相似用户, 通过 $用户 \rightarrow 物品$ 索引, 找到用户近期感兴趣的物品列表 <code>last-n</code></li>
<li>对于召回的 $nk$ 个相似物品, 用公式预估用户对每个物品的兴趣分数并排序</li>
<li>返回分数最高的 100 个物品, 作为召回的结果</li>
</ol>
<p><img src="/../img/recommender-system-usercf-process.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="离散特征处理"><a href="#离散特征处理" class="headerlink" title="离散特征处理"></a>离散特征处理</h1><p>几个离散特征示例:</p>
<ul>
<li>性别: 男, 女两种类别</li>
<li>国籍: 中国, 美国等 200 个国家</li>
<li>英文单词: 常见的几万个英文单词</li>
<li>物品 ID: 商品中的上亿个物品, 每个物品有一个 ID</li>
<li>用户 ID: 系统中的上亿个用户, 每个用户有一个 ID</li>
</ul>
<p>推荐系统需要先将这些离散特征映射为向量:</p>
<ol>
<li>建立字典: 把类别映射为序号, 比如:<br> a. 中国 $\rightarrow 1$<br> b. 美国 $\rightarrow 2$<br> c. 日本 $\rightarrow 3$</li>
<li>向量化: 把序号映射成向量<br> a. One-hot 编码: 把序号映射成高维稀疏向量<br> b. Embedding: 把序号映射成低维稠密向量</li>
</ol>
<h2 id="One-hot-编码"><a href="#One-hot-编码" class="headerlink" title="One-hot 编码"></a>One-hot 编码</h2><p>One-hot 编码会把所有类别都设为一个特征, 取该类别时, 该特征值取 <code>1</code>, 其余特征值取 <code>0</code>.</p>
<p>以性别特征为例, 有 “男”, “女” 两种类别, 先为每种类别编号:</p>
<ul>
<li>$男 \rightarrow 1$</li>
<li>$女 \rightarrow 2$</li>
</ul>
<p>之后用 one-hot 编码为 2 维向量, 如:</p>
<ul>
<li>未知 $\rightarrow$ 0 $\rightarrow$ $[0,0]$</li>
<li>男 $\rightarrow$ 1 $\rightarrow$ $[1,0]$</li>
<li>女 $\rightarrow$ 2 $\rightarrow$ $[0,1]$</li>
</ul>
<p>用国籍为例, 有 “中国”, “美国”, “日本” 等 200 种类别, 先用字典进行编号:</p>
<ul>
<li>$中国 \rightarrow 1$</li>
<li>$美国 \rightarrow 2$</li>
<li>$日本 \rightarrow 3$</li>
</ul>
<p>之后用 one-hot 编码为 200 维稀疏向量:</p>
<ul>
<li>未知 $\rightarrow$ 0 $\rightarrow$ $[0,0,0,0,…,0]$</li>
<li>中国 $\rightarrow$ 1 $\rightarrow$ $[1,0,0,0,…,0]$</li>
<li>美国 $\rightarrow$ 2 $\rightarrow$ $[0,1,0,0,…,0]$</li>
<li>日本 $\rightarrow$ 3 $\rightarrow$ $[0,0,1,0,…,0]$</li>
</ul>
<p>One-hot 编码的局限在于, 对于自然语言等类别很多的问题, 需要几万的维度. 对于推荐系统中有上亿的 ID 编码, 维度达到几亿.</p>
<h2 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h2><p>Embedding 会将类别进行编码, 变为一个低维的稠密矩阵.</p>
<p>以国籍为例:</p>
<p><img src="/../img/recommender-system-embedding-example.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>假设一个类别用一个 <code>4x1</code> 的向量表示</li>
</ul>
<p>Embedding 层的全部参数为 $向量维度 \times 类别数量$, 比如上述例子就是 $4 \times 200 &#x3D; 800$ (就是 embedding 表中的数字个数).</p>
<p>一个好的训练能让相似 embedding 在特征空间中位置相近:</p>
<p><img src="/../img/recommender-system-good-embedding-example.png" srcset="/img/loading.gif" lazyload></p>
<p>Embedding 的计算本质上是:</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">Embedding</span> = 参数矩阵 x <span class="hljs-literal">On</span>e-Hot 向量<br></code></pre></td></tr></table></figure>

<p><img src="/../img/recommender-system-embedding-calculation-example.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="矩阵补充"><a href="#矩阵补充" class="headerlink" title="矩阵补充"></a>矩阵补充</h1><p>矩阵补充 (matrix completion), 是向量召回中最简单的一种方法 (现在不再常用).</p>
<h2 id="为什么叫矩阵补充"><a href="#为什么叫矩阵补充" class="headerlink" title="为什么叫矩阵补充"></a>为什么叫矩阵补充</h2><p>系统中有许多物品, 只有一部分曝光给了用户, 得到兴趣分数, 需要用训练好的模型预估剩下的没有曝光的物品的分数, 补全整个矩阵:</p>
<p><img src="/../img/recommender-system-why-named-matrix-completion.png" srcset="/img/loading.gif" lazyload></p>
<p>当矩阵补充完整, 就能进行推荐了. 直接选出分数高的物品就行.</p>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>训练出能够补全矩阵的模型的结构如下:</p>
<p><img src="/../img/recommender-system-matrix-completion-model-structure.png" srcset="/img/loading.gif" lazyload></p>
<p>应用了两个 embedding layer:</p>
<ul>
<li>内积 $&lt;a, b&gt;$ 越大说明用户对该物品的兴趣分数越大</li>
<li>两个 embedding layer 不共享参数</li>
</ul>
<p>基本的训练思路:</p>
<ul>
<li>用户 embedding 参数矩阵记作 $A$. 第 $u$ 号用户对应矩阵第 $u$ 列, 记作向量 $a_u$</li>
<li>物品 embedding 参数矩阵记作 $B$. 地 $i$ 号物品对应矩阵第 $i$ 列, 记作向量 $b_i$</li>
</ul>
<p><img src="/../img/recommender-system-basic-idea-for-matrix-completion.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>内积 $\langle a_u, b_i \rangle$ 是第 $u$ 号用户对第 $i$ 号物品的兴趣的预估值</li>
<li>训练模型的目的是学习到矩阵 A 和 B, 使得预估值拟合真实观测的兴趣分数</li>
</ul>
<h2 id="数据集准备"><a href="#数据集准备" class="headerlink" title="数据集准备"></a>数据集准备</h2><p>数据集为三元组 <code>(用户ID, 物品ID, 兴趣分数)</code> 的集合, 记作 $\Omega &#x3D; \{(u,i,y)\}$.</p>
<p>数据集中的兴趣分数是系统记录的, 比如:</p>
<ul>
<li>曝光但是没有点击 $\rightarrow$ 0 分</li>
<li>点击, 点赞, 收藏, 转发 $\rightarrow$ 各算 1 分</li>
<li>分数最低是 0, 最高是 4</li>
</ul>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>要把用户 ID, 物品 ID 映射成向量:</p>
<ul>
<li>第 $u$ 号用户 $\rightarrow$ 向量 $a_u$</li>
<li>第 $i$ 号用户 $\rightarrow$ 向量 $b_i$</li>
</ul>
<p>需要求解一个优化问题, 得到参数 $A$ 和 $B$:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>\uderset{A,B}{min} \sum_{(u,i,y) \in \Omega} (y - \langle a_u,b_i \rangle)^2<br>\end{aligned}<br>}<br>$$</p>
<h2 id="模型存储"><a href="#模型存储" class="headerlink" title="模型存储"></a>模型存储</h2><ol>
<li>训练得到矩阵 $A$ 和 $B$<ul>
<li>$A$ 的每一列对应一个用户</li>
<li>$B$ 的每一列对应一个物品</li>
</ul>
</li>
<li>把矩阵 $A$ 的列存储到 <code>key-value</code> 表<ul>
<li><code>key</code> 是用户 <code>ID</code>, <code>value</code> 是 <code>A</code> 的一列</li>
<li>给定用户 <code>ID</code> 时, 能返回一个向量 (也就是这列 embedding 值)</li>
</ul>
</li>
<li>矩阵 $B$ 的存储和索引较复杂</li>
</ol>
<h2 id="线上服务"><a href="#线上服务" class="headerlink" title="线上服务"></a>线上服务</h2><p>当用户使用推荐系统时:</p>
<ol>
<li>把用户 ID 作为 <code>key</code>, 查询 <code>key-value</code> 表, 得到该用户的向量, 记作 <code>a</code></li>
<li>最近邻查找: 查找用户最有可能感兴趣的 <code>k</code> 个物品作为召回结果<ul>
<li>第 <code>i</code> 号物品的 embedding 向量记作 $b_i$</li>
<li>内积 $\langle a, b_i \rangle$ 是用户对第 <code>i</code> 号物品兴趣的预估</li>
<li>返回内积最大的 <code>k</code> 个物品</li>
</ul>
</li>
</ol>
<p>缺点在于, 如果枚举所有物品, 时间复杂度正比于物品数量.</p>
<p>一种加速方法是, 先离散情况对物品做预处理, 划分为几个区域, 每个区域用一个向量表示, 向量长度为 <code>1</code>, 之后建立索引:</p>
<ul>
<li>key 为向量, value 为区域内物品的列表</li>
</ul>
<p><img src="/../img/recommender-system-partition-example.png" srcset="/img/loading.gif" lazyload></p>
<p>此时计算用户 embedding 与区域向量的相似度, 之后与最大值区域内的点进行计算, 返回 <code>top-k</code> 最近邻.</p>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>该方法在实践中效果并不好.</p>
<p>其仅用到了 ID embedding, 没利用物品, 用户属性.</p>
<p>负样本的选取方式不对.</p>
<p>内积不如余弦相似度, 平方损失不如交叉熵损失.</p>
<h1 id="双塔模型"><a href="#双塔模型" class="headerlink" title="双塔模型"></a>双塔模型</h1><p>双塔模型可以看作是矩阵补充的升级版, 其利用了用户和物品的其他特征.</p>
<p>其包含两个塔 (两个神经网络), 用户塔和物品塔各输出一个向量, 两个向量的余弦相似度作为兴趣的预估值.</p>
<h2 id="模型结构-1"><a href="#模型结构-1" class="headerlink" title="模型结构"></a>模型结构</h2><p>对用户的处理:</p>
<ul>
<li>不同的离散特征用不同的 embedding layer</li>
<li>连续特征用归一化, 分桶等处理</li>
</ul>
<p><img src="/../img/recommender-system-two-tower-deal-user.png" srcset="/img/loading.gif" lazyload></p>
<p>对物品的处理类似:</p>
<p><img src="/../img/recommender-system-two-tower-deal-item.png" srcset="/img/loading.gif" lazyload></p>
<p>整个模型结构:</p>
<p><img src="/../img/recommender-system-two-tower-structure.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>用户塔, 物品塔各输出一个向量</li>
<li>余弦向量表示两个向量的夹角</li>
</ul>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>模型训练的常见方法有:</p>
<ul>
<li>Pointwise: 独立看待每个正样本, 负样本, 做简单的二元分类</li>
<li>Pairwise: 每次取一个正样本, 一个负样本</li>
<li>Listwise: 每次取一个正样本, 多个负样本</li>
</ul>
<p>这里正负样本的选择:</p>
<ul>
<li>正样本: 用户点击的物品</li>
<li>负样本: 可以是:<ul>
<li>没有被召回的</li>
<li>召回但是被粗排, 精排淘汰的</li>
<li>曝光但是未点击的</li>
</ul>
</li>
</ul>
<p>可参考这些文献:</p>
<ol>
<li><code>Jui-Ting Huang et al. Embedding-based Retrieval in Facebook Search. In KDD, 2020</code></li>
<li><code>Xinyang Yi et al. Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations. In RecSys, 2019.</code></li>
</ol>
<h2 id="Pointwise-训练"><a href="#Pointwise-训练" class="headerlink" title="Pointwise 训练"></a>Pointwise 训练</h2><p>Pointwise 是最简单的训练方式, 把召回看作是二元分类任务.</p>
<p>对于正样本, 鼓励 $cos(a,b)$ 接近 $+1$.</p>
<p>对于负样本, 鼓励 $cos(a,b)$ 接近 $-1$.</p>
<p>一般需要控制正负样本数量为 $1:2$ 或者 $1:3$ (原因不明虽然).</p>
<h2 id="Pairwise-训练"><a href="#Pairwise-训练" class="headerlink" title="Pairwise 训练"></a>Pairwise 训练</h2><p>做训练时, 每组的输入是一个三元组, 包括 <code>(物品正样本, 用户, 物品负样本)</code>:</p>
<p><img src="/../img/recommender-system-pairwise-structure-example.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>特征变换的 embedding 层和神经网络共享参数</li>
<li>需要让 $cos(a,b^+)$ 接近 $+1$</li>
<li>需要让 $cos(a,b^-)$ 接近 $-1$</li>
</ul>
<p>做 Pairwise 训练的基本想法是, 鼓励用户对正样本的兴趣大于负样本, 也就是 $cos(a,b^+) &gt; cos(a,b^-)$, 且两者之差越大越好.</p>
<p>损失函数:</p>
<ul>
<li>如果 $cos(a,b^+) &gt; cos(a,b^-) + m$, 则没有损失</li>
<li>否则, 损失等于 $cos(a,b^-) + m - cos(a,b^+)$</li>
<li>得到:</li>
</ul>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>L(a,b^+,b^-) &#x3D; max\{0, cos(a,b^-) + m - cos(a,b^+)\}<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>$m$ 是需要手动设置的超参数</li>
</ul>
<p>即 triplet hinge loss.</p>
<p>还有其他损失函数可用, 比如 triplet logistic loss:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>L(a,b^+,b^-) &#x3D; log(1 + exp[\sigma \cdot (cos(a,b^-) - cos(a,b^+))])<br>\end{aligned}<br>}<br>$$</p>
<ul>
<li>$\sigma$ 是需要手动设置的超参数</li>
</ul>
<p>通过最小化上述损失函数来训练模型.</p>
<h2 id="Listwise-训练"><a href="#Listwise-训练" class="headerlink" title="Listwise 训练"></a>Listwise 训练</h2><p>Listwise 训练时, 每次取一个正样本和多个负样本.</p>
<p>一条数据包含:</p>
<ul>
<li>一个用户, 特征向量记作 $a$</li>
<li>一个正样本, 特征向量记作 $b^+$</li>
<li>多个负样本, 特征向量记作 $b_1^-,…,b_n^-$</li>
</ul>
<p>要鼓励 $cos(a,b^+)$ 尽量大.</p>
<p>要鼓励 $cos(a,b_1^-),…,cos(a,b_n^-)$ 尽量小.</p>
<p><img src="/../img/recommender-system-listwise-structure.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><code>softmax</code> 输出分数, 正样本的分数越大越好, 接近 <code>1</code>. 负样本的分数越小越好, 接近 <code>0</code></li>
<li>训练时, 将正样本的标签设为输出 <code>1</code>, 负样本为 <code>0</code></li>
</ul>
<h2 id="正样本选择"><a href="#正样本选择" class="headerlink" title="正样本选择"></a>正样本选择</h2><p>正样本一般选择: 曝光而且有点击的 “用户-物品” 二元组 (用户对物品感兴趣).</p>
<p>但由于少部分物品会占据大部分点击, 会导致正样本大多是热门物品, 解决方案是: 对冷门物品用过采样, 对热门物品用降采样:</p>
<ul>
<li>过采样 (up-sampling), 指让一个样本出现多次</li>
<li>降采样 (down-sampling), 指抛弃一些样本</li>
</ul>
<h2 id="负样本选择"><a href="#负样本选择" class="headerlink" title="负样本选择"></a>负样本选择</h2><p><img src="/../img/recommender-system-how-to-chose-negative-sample.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="简单负样本"><a href="#简单负样本" class="headerlink" title="简单负样本"></a>简单负样本</h3><p>简单负样本指未被召回的物品, 大概率是用户不感兴趣的. 在全部物品达上亿规模时, $未被召回的物品 \approx 全体物品$. 因此直接从全体物品中做抽样, 作为负样本.</p>
<p>如果完全均匀抽取, 会对冷门物品不公平:</p>
<ul>
<li>因为正样本大多是热门物品</li>
<li>均匀采样出的负样本, 大多是冷门物品</li>
</ul>
<p>这会导致热门物品越热 (每次都做正样品, 容易被推荐), 冷门物品越冷 (每次都做负样品, 更不会被推荐).</p>
<p>因此采用非均匀抽样, 打压热门物品:</p>
<ul>
<li>负样本的抽样概率与热门程度 (点击次数) 正相关</li>
<li>比如 $抽样概率 \propto (点击次数)^{0.75}$</li>
</ul>
<p>另一种简单负样本: batch 内负样本例子:</p>
<p><img src="/../img/recommender-system-in-batch-negative-sample-example.png" srcset="/img/loading.gif" lazyload></p>
<p>但这会导致热门物品成为负样本的概率过大 $\propto 点击次数$. 可以参考 <code>Xinyang Yi et al. Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations. In RecSys, 2019.</code> 来修正偏差.</p>
<h3 id="困难负样本"><a href="#困难负样本" class="headerlink" title="困难负样本"></a>困难负样本</h3><p>困难负样本, 指:</p>
<ul>
<li>被粗排淘汰的物品 (比较困难)</li>
<li>精排分数靠后的物品 (非常困难, 与正样本很相似, 难以分类正确)</li>
</ul>
<p>之所以称困难负样本, 因为其容易被模型分错, 认定为正样本. 这些物品用户可能感兴趣, 但是还不够感兴趣.</p>
<hr>
<p>业界通常混合几种负样本, 比如:</p>
<ul>
<li><code>50%</code> 简单负样本</li>
<li><code>50%</code> 困难负样本</li>
</ul>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>训练召回模型时不能把 <code>曝光但是没有点击</code> 的物品作为负样本:</p>
<p><img src="/../img/recommender-system-can-not-used-in-recall.png" srcset="/img/loading.gif" lazyload></p>
<p>因为召回的目标是找到用户可能感兴趣的物品, 而不是区分比较感兴趣和非常感兴趣, 上述物品就属于 “比较感兴趣” 的范畴, 不该在召回时被剔除. 更何况可能是用户 “非常感兴趣” 但是碰巧没有点击.</p>
<p>这部分物品更适合做召回的正样本.</p>
<h2 id="线上召回-1"><a href="#线上召回-1" class="headerlink" title="线上召回"></a>线上召回</h2><p>训练好的两个塔分别用于提取用户特征和物品特征:</p>
<p><img src="/../img/recommender-system-after-train-two-tower.png" srcset="/img/loading.gif" lazyload></p>
<p>在开始线上服务之前, 先用物品塔提取所有物品的特征, 并把 $\langle 特征向量b, 物品ID\rangle$ 保存到向量数据库中, 便于后续的最近邻查找:</p>
<p><img src="/../img/recommender-system-store-item-vector-in-database.png" srcset="/img/loading.gif" lazyload></p>
<p>而对于用户塔, 对用户的处理则完全不同, 不需要事先提取并存储向量, 而是在用户发起时, 线上计算向量 <code>a</code>, 然后用向量 <code>a</code> 向 item 发起 query 查找最近邻:</p>
<p><img src="/../img/recommender-system-user-tower-recall.png" srcset="/img/loading.gif" lazyload></p>
<p>不事先存储用户向量的原因是: 用户兴趣动态变化, 而物品特征相对稳定.</p>
<h2 id="模型更新"><a href="#模型更新" class="headerlink" title="模型更新"></a>模型更新</h2><h3 id="全量更新"><a href="#全量更新" class="headerlink" title="全量更新"></a>全量更新</h3><p>全量更新指, 用昨天全天的数据训练模型:</p>
<ul>
<li>在昨天模型参数的基础上做训练</li>
<li>昨天的数据只训练 1 epoch, 即每天数据只用一遍</li>
<li>发布新的用户塔神经网络和物品向量, 供线上召回使用</li>
</ul>
<h3 id="增量更新"><a href="#增量更新" class="headerlink" title="增量更新"></a>增量更新</h3><p>增量更新指, 做 online learning 更新模型参数, 每隔几十分钟发布新的参数:</p>
<ul>
<li>因为用户的兴趣会随时发生变化</li>
<li>需要实时收集线上数据, 做流式处理</li>
<li>对模型做 online learning 时, 增量更新 ID Embedding 参数 (不更新神经网络其他部分的参数)</li>
<li>发布用户 ID Embedding, 供用户塔线上计算用户向量</li>
</ul>
<hr>
<p>注意:</p>
<p><img src="/../img/recommender-system-why-two-increase-model.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="双塔模型-自监督学习"><a href="#双塔模型-自监督学习" class="headerlink" title="双塔模型 + 自监督学习"></a>双塔模型 + 自监督学习</h1><p>自监督学习的目的是让物品塔的效果更好.</p>
<p>在推荐系统中, 头部效应严重:</p>
<ul>
<li>少部分物品占据了大部分点击</li>
<li>大部分物品的点击次数不高</li>
</ul>
<p>高点击物品的表征学得好, 而长尾物品的表征学得不好.</p>
<p>自监督学习会通过 data augmentation 来加强学习长尾物品的向量表征 (可以参考 <code>Tiansheng Yao et al. Self-supervised Learning for Large-scale Item Recommendations. In CIKM, 2021.</code>).</p>
<h2 id="Listwise-训练的损失函数"><a href="#Listwise-训练的损失函数" class="headerlink" title="Listwise 训练的损失函数"></a>Listwise 训练的损失函数</h2><p><img src="/../img/recommender-system-loss-for-listwise.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="纠偏"><a href="#纠偏" class="headerlink" title="纠偏"></a>纠偏</h2><p>在训练时, 把 $cos(a_i, b_j)$ 替换为:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>cos(a_i, b_j) - \log p_j<br>\end{aligned}<br>}<br>$$</p>
<p>在线上召回时不需要这个替换.</p>
<h2 id="自监督学习"><a href="#自监督学习" class="headerlink" title="自监督学习"></a>自监督学习</h2><p>一个特征的多个变换训练出的向量应该有高相似度:</p>
<p><img src="/../img/recommender-system-item-tower-data-augmentation.png" srcset="/img/loading.gif" lazyload></p>
<p>但不同特征间应该有低相似度:</p>
<p><img src="/../img/recommender-system-self-supervised-learning-similarity.png" srcset="/img/loading.gif" lazyload></p>
<p>常见的特征变换有:</p>
<ul>
<li>Random Mask: 随机选一些离散特征, 把它们遮住. 比如:<ul>
<li>某物品的类目特征是 $u &#x3D; \{数码,摄影\}$</li>
<li>Mask 后的类目特征是 $u’ &#x3D; \{default\}$</li>
</ul>
</li>
<li>Dropout: 随机丢弃一些值, 仅对多值离散特征生效, 比如:<ul>
<li>某物品的类目特征是 $u &#x3D; \{美妆,摄影\}$</li>
<li>Dropout 后的类目特征是 $u’ &#x3D; \{美妆\}$</li>
</ul>
</li>
<li>Complementary (互补特征), 把特征分为两组, 交替启用, 比如:<ul>
<li>物品有 4 种特征: ID, 类目, 关键词, 城市</li>
<li>随机分为两组: <code>&#123;ID, 关键词&#125;</code> 和 <code>&#123;类目, 城市&#125;</code></li>
<li>先用 ${ID, default, 关键词, default} \rightarrow 物品表征$</li>
<li>再用 ${default, 类目, default, 城市} \rightarrow 物品表征$</li>
<li>鼓励两个表征的向量相似</li>
</ul>
</li>
<li>Mask 一组关联的特征, 比如类目和性别的关联:</li>
</ul>
<p><img src="/../img/recommender-system-related-mask-features.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/../img/recommender-system-cal-two-related-features.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/../img/recommender-system-how-to-do-mask-related.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p><img src="/../img/recommender-system-learn-with-self-supervised.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="Deep-Retrieval-召回"><a href="#Deep-Retrieval-召回" class="headerlink" title="Deep Retrieval 召回"></a>Deep Retrieval 召回</h1><p>Deep Retrieval 把物品表征为路径 (path), 线上查找用户最匹配的路径. (可参考 <code>Weihao Gao et al. Learning A Retrievable Structure for Large-Scale Recommendations. In CIKM, 2021.</code>)</p>
<p>Deep Retrieval 部分的讲解流程 (就这个视频教程的):</p>
<ol>
<li>索引:<br> a. $路径 \rightarrow List\langle 物品 \rangle$<br> b. $物品 \rightarrow List\langle 路径 \rangle$ </li>
<li>预估模型: 神经网络预估用户对路径的兴趣</li>
<li>线上召回: $用户 \rightarrow 路径 \rightarrow 物品$</li>
<li>训练:<br> a. 学习神经网络参数, 学习用户对物品的兴趣<br> b. 学习物品表征 ($物品 \rightarrow 路径$), 将物品映射到路径</li>
</ol>
<p>召回时, 先取回用户最感兴趣的路径, 再取回路径上的物品. 找到用户最感兴趣的路径需要用到神经网络:</p>
<ul>
<li>给定用户特征 $x$, 用神经网络预估用户对路径 $path &#x3D; [a,b,c]$ 的兴趣, 分数记作 $p(path|x)$</li>
<li>召回过程中通过 beam search 寻找分数最高的 <code>s</code> 条路径</li>
<li>利用索引 $path \rightarrow List\langle item \rangle$ 召回每条路径上的 <code>n</code> 个物品</li>
<li>一共召回 $s \times n$ 个物品, 对物品做初步排序, 返回分数最高的若干物品</li>
</ul>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>索引用于关联物品和路径.</p>
<p>物品表征为路径的示例:</p>
<p><img src="/../img/recommender-system-item-as-path-example.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>深度: <code>depth = 3</code></li>
<li>宽度: <code>width = K</code></li>
<li>把一个物品表示为一条路径, 比如 <code>[2, 4, 1]</code></li>
<li>一个物品可以表示为多条路径, 如 <code>&#123;[2, 4, 1], [4, 1, 1]&#125;</code></li>
</ul>
<p>第一种索引 $item \rightarrow List\langle path \rangle$:</p>
<ul>
<li>一个物品对应多条路径</li>
<li>用 3 个节点表示一条路径: <code>path = [a, b, c]</code> (<code>depth=3</code> 的情况)</li>
</ul>
<p>第二种索引 $path \rightarrow List\langle item \rangle$:</p>
<ul>
<li>一条路径对应多个物品, 召回时, 用一条路径取回多个物品</li>
</ul>
<h2 id="预估模型"><a href="#预估模型" class="headerlink" title="预估模型"></a>预估模型</h2><p>Deep retrieval 中设计了一种神经网络: 给定用户特征, 神经网络可以预估用户对路径的兴趣分数, 这样可以根据用户特征召回多条路径</p>
<ul>
<li>用 3 个节点表示一条路径: <code>path = [a,b,c]</code></li>
<li>给定用户特征 $x$, 预估用户对节点 $a$ 的兴趣 $p_1(a|x)$</li>
<li>给定 $x$ 和 $a$, 预估用户对节点 $b$ 的兴趣 $p_2(b|a;x)$</li>
<li>给定 $x,a,b$, 预估用户对节点 $c$ 的兴趣 $p_3(c|a,b;x)$</li>
<li>预估用户对 <code>path = [a,b,c]</code> 的兴趣:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>p(a,b,c|x) &#x3D; p_1 (a|x) \times p_2 (b|a;x) \times p_3(c|a,b;x)<br>\end{aligned}<br>}<br>$$</li>
</ul>
<p><img src="/../img/deep-retrivel-get-path-example.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="线上召回-2"><a href="#线上召回-2" class="headerlink" title="线上召回"></a>线上召回</h2><p>线上召回负责, 给定用户特征, 返回一批物品: $用户 \rightarrow 路径 \rightarrow 物品$:</p>
<ol>
<li>给定用户特征, 用 beam search 召回一批路径</li>
<li>利用索引 $path \rightarrow List\langle item \rangle$ 召回一批物品</li>
<li>对物品做打分和排序, 选出一个子集</li>
</ol>
<h3 id="Beam-search"><a href="#Beam-search" class="headerlink" title="Beam search"></a>Beam search</h3><p>假设有 3 层, 每层 K 个节点, 共 $K^3$ 条路径. 用神经网络给所有 $K^3$ 条路径打分, 计算量比较大, 因此这里采用 beam search 来减少计算量 (每层选分数最大的 n 个节点), 需要设置超参数 <code>beam size</code> (选中的路径数量), 比如 <code>beam size=1</code>:</p>
<p><img src="/../img/recommender-system-beam-search-with-size-1.png" srcset="/img/loading.gif" lazyload></p>
<p><code>beam size=4</code> 的例子:</p>
<p><img src="/../img/recommender-system-beam-size-4-example1.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h2><p>训练部分需要同时学习神经网络参数和物品表征:</p>
<ul>
<li><p>神经网络预估用户对路径 <code>[a,b,c]</code> 的兴趣分数记作 $p(a,b,c|x)$</p>
</li>
<li><p>把一个物品表征为多条路径 <code>&#123;[a,b,c]&#125;</code>, 以建立索引:</p>
<ul>
<li>$item \rightarrow List\langle path \rangle$</li>
<li>$path \rightarrow List\langle item \rangle$</li>
</ul>
</li>
<li><p>训练时只用到正样本 <code>(user, item)</code>: <code>click(user,item) = 1</code>, 即只要点过就能算正样本</p>
</li>
</ul>
<p>学习神经网络参数的过程, 假设:</p>
<ul>
<li>物品表征为 $J$ 条路径: $[a_1,b_1,c_1],…,[a_J,b_J,c_J]$</li>
<li>此时用户对路径 <code>[a,b,c]</code> 的兴趣为:<ul>
<li>$p(a,b,c|x) &#x3D; p_1(a|x) \times p_2(b|a;x) \times p_3(c|a,b;x)$</li>
</ul>
</li>
<li>如果用户点击过物品, 说明用户对 J 条路径感兴趣, 此时要:<ul>
<li>让 $\sum_{j&#x3D;1}^J p(a_j,b_j,c_j|x)$ 变大</li>
<li>损失函数: $loss &#x3D; -log(\sum_{j&#x3D;1}^J p(a_j,b_j,c_j|x))$</li>
</ul>
</li>
</ul>
<p>学习物品表征的过程:</p>
<ul>
<li>用户 <code>user</code> 对路径 <code>path=[a,b,c]</code> 的兴趣记作:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>p(path|user) &#x3D; p(a,b,c|x)<br>\end{aligned}<br>}<br>$$</li>
<li>物品 <code>item</code> 与路径 <code>path</code> 的相关性:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>score(item, patth) &#x3D; \sum_{user} p(path|user) \times click(user,item)<br>\end{aligned}<br>}<br>$$</li>
<li>根据 <code>score(item,path)</code> 选出 J 条路径作为 <code>item</code> 的表征, $\Pi &#x3D; \{path_1,…,path_j\}$</li>
</ul>
<p><img src="/../img/recommender-system-how-item-to-path.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>损失函数: $loss(item,\Pi) &#x3D; -\log (\sum_{j&#x3D;1}^J score(item,path_j))$</li>
</ul>
<p>训练部分的总结:</p>
<p><img src="/../img/recommender-system-deep-retrievel-train-process.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="其他召回"><a href="#其他召回" class="headerlink" title="其他召回"></a>其他召回</h1><h2 id="地理位置召回"><a href="#地理位置召回" class="headerlink" title="地理位置召回"></a>地理位置召回</h2><p>GeoHash 召回是一种地理位置召回, 之所以用这个信息:</p>
<ul>
<li>用户可能对附近发生的事感兴趣</li>
<li>GeoHash: 会对经纬度进行编码, 表示地图上一个长方形的区域</li>
<li>系统维护一个索引: $GeoHash \rightarrow 优质物品列表(按时间倒排)$</li>
</ul>
<p>在做召回时, 通过 <code>GeoHash</code> 取回物品列表. 该通道没有个性化, 只与地理位置相关.</p>
<p>同城召回也是一种地理召回, 和 GeoHash 几乎一致, 只不过用城市作为索引:</p>
<ul>
<li>用户可能对同城 (用户所在城市或曾经居住过的城市) 发生的事感兴趣</li>
<li>索引: $城市 \rightarrow 优质物品列表(按时间倒排)$</li>
<li>同样没有个性化</li>
</ul>
<h2 id="作者召回"><a href="#作者召回" class="headerlink" title="作者召回"></a>作者召回</h2><p>如果你对一个作者感兴趣, 系统则会召回该作者新发布的笔记.</p>
<p>系统会维护两个索引:</p>
<ul>
<li>$用户 \rightarrow 关注的作者$</li>
<li>$作者 \rightarrow 发布的笔记$</li>
</ul>
<p>线上召回时, 会根据用户 ID, 找到其关注的作者, 然后取回笔记.</p>
<p>也可以是有交互的作者召回:</p>
<ul>
<li>如果用户对某笔记感兴趣 (点赞, 收藏, 转发), 那么用户可能对该作者的其他笔记感兴趣, 即使没有关注</li>
<li>系统维护一个索引: $用户 \rightarrow 有交互的作者$</li>
</ul>
<p>线上召回时, 给定用户 ID, 找到有交互的作者, 取回其最新笔记.</p>
<p>还可以是相似作者召回:</p>
<ul>
<li>如果用户喜欢某作者, 那么用户会喜欢相似的作者</li>
<li>系统维护一个索引: $作者 \rightarrow 相似作者$</li>
</ul>
<p>线上召回时, 给定用户 ID, 找到其感兴趣的作者, 然后找到相似作者, 找回其最新的笔记.</p>
<h2 id="缓存召回"><a href="#缓存召回" class="headerlink" title="缓存召回"></a>缓存召回</h2><p>缓存召回的想法是复用前 n 次推荐精排的结果.</p>
<p>因为物品能通过精排, 已经非常不容易, 如果只是因为重排时做多样性抽样没有曝光, 则非常浪费.</p>
<p>可以选择精排中的 <code>top-k</code> 且没有曝光的, 缓存起来作为一条召回通道.</p>
<p>由于缓存大小固定, 需要退场机制:</p>
<ul>
<li>一旦笔记成功曝光, 就从缓存退场</li>
<li>如果超出缓存大小, 就移除最先进入缓存的笔记</li>
<li>每篇笔记最多保存 3 天, 达到 3 天就退场</li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/AI/" class="category-chain-item">AI</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Recommender-system-基础</div>
      <div>http://example.com/2025/08/20/Recommender-system-基础/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Jie</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年8月20日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/08/22/RNN-%E5%9F%BA%E7%A1%80/" title="RNN-基础">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">RNN-基础</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/08/19/%E6%B5%85%E6%8B%B7%E8%B4%9D%E5%92%8C%E6%B7%B1%E6%8B%B7%E8%B4%9D/" title="浅拷贝和深拷贝">
                        <span class="hidden-mobile">浅拷贝和深拷贝</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'zKurisu/comments-utterances');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Jie</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Orkarin</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
