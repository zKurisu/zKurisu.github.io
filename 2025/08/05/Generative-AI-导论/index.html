

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/wallhaven-j5kjgy_1920x1080.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Jie">
  <meta name="keywords" content="">
  
    <meta name="description" content="课程作业替换版 该文章用作李宏毅老师 2024春 “生成式人工智能导论” 课程的笔记. 第一讲 生成式AI是什么Generative AI 可以定义为: 让机器产生有复杂 (指无法穷举) 结构的物件. 比如:  文章, 由文字组成 图像, 由像素组成 语音, 由采样点组成  其为 AI 的一种:  有些问题不属于 generative ai, 比如 classification, 从有限的选项中做">
<meta property="og:type" content="article">
<meta property="og:title" content="Generative-AI-导论">
<meta property="og:url" content="http://example.com/2025/08/05/Generative-AI-%E5%AF%BC%E8%AE%BA/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="课程作业替换版 该文章用作李宏毅老师 2024春 “生成式人工智能导论” 课程的笔记. 第一讲 生成式AI是什么Generative AI 可以定义为: 让机器产生有复杂 (指无法穷举) 结构的物件. 比如:  文章, 由文字组成 图像, 由像素组成 语音, 由采样点组成  其为 AI 的一种:  有些问题不属于 generative ai, 比如 classification, 从有限的选项中做">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/generative-ai-in-ai.png">
<meta property="og:image" content="http://example.com/img/generative-ai-what-is-machine-learning.png">
<meta property="og:image" content="http://example.com/img/generative-ai-model-is-function.png">
<meta property="og:image" content="http://example.com/img/generative-ai-neural-network-takes-parameters.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-these-concept-connect.png">
<meta property="og:image" content="http://example.com/img/generative-ai-transformer-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-to-solve-infinity.png">
<meta property="og:image" content="http://example.com/img/generative-ai-generative-strategy-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-chatgpt-work-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-why-not-select-major-prob-one.png">
<meta property="og:image" content="http://example.com/img/generative-ai-token-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-work-in-wrong-way.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-gpt-see-history.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-data-come.png">
<meta property="og:image" content="http://example.com/img/generative-ai-chatgpt-parameter-and-data-dev.png">
<meta property="og:image" content="http://example.com/img/generative-ai-human-help-learn.png">
<meta property="og:image" content="http://example.com/img/generative-ai-reinforcement-learning-start.png">
<meta property="og:image" content="http://example.com/img/generative-ai-reinforcement-learning-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-reinforcement-learning-add-reward-model.png">
<meta property="og:image" content="http://example.com/img/generative-ai-why-called-alignment.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-to-make-ai-better.png">
<meta property="og:image" content="http://example.com/img/generative-ai-find-best-parameters.png">
<meta property="og:image" content="http://example.com/img/generative-ai-one-way-to-explain-result.png">
<meta property="og:image" content="http://example.com/img/generative-ai-second-steps-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-adapter-works.png">
<meta property="og:image" content="http://example.com/img/generative-ai-re-look-three-stages.png">
<meta property="og:image" content="http://example.com/img/generative-ai-instruction-fine-tuning-vs-rlhf.png">
<meta property="og:image" content="http://example.com/img/generative-ai-train-a-reward-model.png">
<meta property="og:image" content="http://example.com/img/generative-ai-rl-what-is-good.png">
<meta property="og:image" content="http://example.com/img/generative-ai-agent-possible-work.png">
<meta property="og:image" content="http://example.com/img/generative-ai-modle-dev.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-language-model-work-flow.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-tokenization-work.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-embedding-works.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-position-works.png">
<meta property="og:image" content="http://example.com/img/generative-ai-why-attention-is-all-you-need.png">
<meta property="og:image" content="http://example.com/img/generative-ai-attention-example1.png">
<meta property="og:image" content="http://example.com/img/generative-ai-attention-calculate-relation.png">
<meta property="og:image" content="http://example.com/img/generative-ai-attention-weight-comes.png">
<meta property="og:image" content="http://example.com/img/generative-ai-attention-output.png">
<meta property="og:image" content="http://example.com/img/generative-ai-attention-matrix-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-multi-head-attention.png">
<meta property="og:image" content="http://example.com/img/generative-ai-multi-head-attention-output.png">
<meta property="og:image" content="http://example.com/img/generative-ai-add-feed-forward-layer.png">
<meta property="og:image" content="http://example.com/img/generative-ai-transformer-block-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-transformer-output.png">
<meta property="og:image" content="http://example.com/img/generative-ai-attention-related-papers.png">
<meta property="og:image" content="http://example.com/img/generative-ai-larger-model-have-ability-to-learn-mul.png">
<meta property="og:image" content="http://example.com/img/generative-ai-analyze-embedding.png">
<meta property="og:image" content="http://example.com/img/generative-ai-convert-embedding-to-two-dimension.png">
<meta property="og:image" content="http://example.com/img/generative-ai-is-correct-ai-output.png">
<meta property="og:image" content="http://example.com/img/generative-ai-seq2seq-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-seq2seq-model-structure.png">
<meta property="og:image" content="http://example.com/img/generative-ai-encoder-structure.png">
<meta property="og:image" content="http://example.com/img/generative-ai-residual-structure-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-decoder-process-begin.png">
<meta property="og:image" content="http://example.com/img/generative-ai-decoder-end-process.png">
<meta property="og:image" content="http://example.com/img/generative-ai-decoder-structure-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-self-attention-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-masked-self-attention-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-nat-vs-at-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-encoder-connect-to-decoder.png">
<meta property="og:image" content="http://example.com/img/generative-ai-cross-attention-detail.png">
<meta property="og:image" content="http://example.com/img/generative-ai-train-transformer-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-scheduled-sampling-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-what-is-benchmark.png">
<meta property="og:image" content="http://example.com/img/generative-ai-with-image-and-video.png">
<meta property="og:image" content="http://example.com/img/generative-ai-frame-compose-image.png">
<meta property="og:image" content="http://example.com/img/generative-ai-video-compose-of-frame.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-ai-saw-image.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-to-deal-video.png">
<meta property="og:image" content="http://example.com/img/generative-ai-common-problem-for-image.png">
<meta property="og:image" content="http://example.com/img/generative-ai-extract-info-from-image.png">
<meta property="og:image" content="http://example.com/img/generative-ai-vae-and-flow-based-method.png">
<meta property="og:image" content="http://example.com/img/generative-ai-diffusion-model-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-how-to-train-diffusion-model.png">
<meta property="og:image" content="http://example.com/img/generative-ai-diffusion-process.png">
<meta property="og:image" content="http://example.com/img/generative-ai-gan-method-example.png">
<meta property="og:image" content="http://example.com/img/generative-ai-gan-with-other-method.png">
<meta property="article:published_time" content="2025-08-05T12:40:10.000Z">
<meta property="article:modified_time" content="2025-08-11T05:56:13.412Z">
<meta property="article:author" content="Jie">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/generative-ai-in-ai.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Generative-AI-导论 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  



  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Jie</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/SteinsGate_all.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Generative-AI-导论"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-08-05 20:40" pubdate>
          2025年8月5日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.4k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          37 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Generative-AI-导论</h1>
            
            
              <div class="markdown-body">
                
                <p><a target="_blank" rel="noopener" href="https://github.com/Hoper-J/LLM-Guide-and-Demos-zh_CN">课程作业替换版</a></p>
<p>该文章用作<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1BJ4m1e7g8?spm_id_from=333.788.player.switch&vd_source=bc8ddbb1a08707dc809c3fd9bb85290d&p=2">李宏毅老师 2024春 “生成式人工智能导论” 课程</a>的笔记.</p>
<h1 id="第一讲-生成式AI是什么"><a href="#第一讲-生成式AI是什么" class="headerlink" title="第一讲 生成式AI是什么"></a>第一讲 生成式AI是什么</h1><p>Generative AI 可以定义为: 让机器产生有复杂 (指无法穷举) 结构的物件. 比如:</p>
<ul>
<li>文章, 由文字组成</li>
<li>图像, 由像素组成</li>
<li>语音, 由采样点组成</li>
</ul>
<p>其为 AI 的一种:</p>
<p><img src="/../img/generative-ai-in-ai.png" srcset="/img/loading.gif" lazyload></p>
<p>有些问题不属于 generative ai, 比如 classification, 从有限的选项中做选择.</p>
<p>另一个概念, 机器学习: 让机器自动从数据中找到一个函数.</p>
<p><img src="/../img/generative-ai-what-is-machine-learning.png" srcset="/img/loading.gif" lazyload></p>
<p>很多时候, 模型就是指 “带有大量参数的函数”.</p>
<p><img src="/../img/generative-ai-model-is-function.png" srcset="/img/loading.gif" lazyload></p>
<p>机器学习的过程就是找参数的过程. 而在深度学习中, 这些参数的联系用 neural network 来表示.</p>
<p><img src="/../img/generative-ai-neural-network-takes-parameters.png" srcset="/img/loading.gif" lazyload></p>
<p>此时可以观察几个概念的关系:</p>
<p><img src="/../img/generative-ai-how-these-concept-connect.png" srcset="/img/loading.gif" lazyload></p>
<p>以 ChatGPT 为例, 其也可以视作一个函数, 但是有上亿个参数. 其背后使用一种类神经网络模型, Transformer:</p>
<p><img src="/../img/generative-ai-transformer-example.png" srcset="/img/loading.gif" lazyload></p>
<p>通过大量的含输入和输出的数据, 通过机器学习把上亿个参数找出来, 就是训练好了一个模型.</p>
<p>文本生成的核心通俗来讲是 “文字接龙”, 将原本的目标拆解成一连串的文字接龙:</p>
<p><img src="/../img/generative-ai-how-to-solve-infinity.png" srcset="/img/loading.gif" lazyload></p>
<p>这种生成策略称 “Autoregressive Generation”:</p>
<p><img src="/../img/generative-ai-generative-strategy-example.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="了解大型语言模型"><a href="#了解大型语言模型" class="headerlink" title="了解大型语言模型"></a>了解大型语言模型</h2><p>同样以 ChatGPT 为例, 从名称入手:</p>
<ul>
<li>G, Generative, 生成</li>
<li>P, Pre-trained, 预训练</li>
<li>T, Transformer</li>
</ul>
<p><img src="/../img/generative-ai-chatgpt-work-example.png" srcset="/img/loading.gif" lazyload></p>
<p>通过几率分布随机输出. 这也导致同样的问题, 每次回答都会不同.</p>
<p>为什么会选择掷骰子, 而不是直接选择概率最大的呢?</p>
<p><img src="/../img/generative-ai-why-not-select-major-prob-one.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>后者可能会导致, 不断输出同样的句子</li>
</ul>
<p><code>Token</code> 的定义可能不同, 不一定是一个字符或者一个词汇 (不同的语言模型通常不同), 比如:</p>
<p><img src="/../img/generative-ai-token-example.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>英文单字不用做 token, 因为其无法穷举</li>
</ul>
<p>单用文字接龙, 也会导致大语言模型可能会瞎掰扯, 比如课程中的例子, 让 ChatGPT 描述一个不存在的节日以及网址:</p>
<p><img src="/../img/generative-ai-work-in-wrong-way.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>模型只关注如何文字接龙出来而已, 而非真实性</li>
</ul>
<p>早期 ChatGPT 实现多段连续对话的技巧是将以前用户的问题以及自己的回答都作为下一次生成的输入:</p>
<p><img src="/../img/generative-ai-how-gpt-see-history.png" srcset="/img/loading.gif" lazyload></p>
<p>任何的句子, 都能作为训练素材, 比如:</p>
<p><img src="/../img/generative-ai-how-data-come.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>让模型知道, 输入 “人” 时, 让输出 “工” 的概率增大, 以此类推</li>
</ul>
<p>GPT 系列的参数量以及训练的文本量演变:</p>
<p><img src="/../img/generative-ai-chatgpt-parameter-and-data-dev.png" srcset="/img/loading.gif" lazyload></p>
<p>早期的 GPT 是自监督式学习, 后续引入监督式学习后, 准确率有所提高:</p>
<p><img src="/../img/generative-ai-human-help-learn.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>模型在预训练后, 不需要提供太多数据来进行监督式学习</li>
</ul>
<p>在监督学习调整后, 还可进行强化学习 (Reinforcement learning), 此时给模型提供回馈, 而非正确答案:</p>
<p><img src="/../img/generative-ai-reinforcement-learning-start.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/../img/generative-ai-reinforcement-learning-example.png" srcset="/img/loading.gif" lazyload></p>
<p>可以在人工回馈的同时训练 Reward model, 从而让其自动训练:</p>
<p><img src="/../img/generative-ai-reinforcement-learning-add-reward-model.png" srcset="/img/loading.gif" lazyload></p>
<p>监督式学习和强化学习的工程可以称为 “Alignment” (对齐, 即对齐人类的需求):</p>
<p><img src="/../img/generative-ai-why-called-alignment.png" srcset="/img/loading.gif" lazyload></p>
<p>有时语言模型突然阶段, 可能是输出到了 EOF 字符 (毕竟都是概率). </p>
<h1 id="第二讲-今日的生成式人工智能厉害在哪里"><a href="#第二讲-今日的生成式人工智能厉害在哪里" class="headerlink" title="第二讲 今日的生成式人工智能厉害在哪里?"></a>第二讲 今日的生成式人工智能厉害在哪里?</h1><p><img src="/../img/generative-ai-how-to-make-ai-better.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="第六讲-大语言模型修炼史-第一阶段-Pre-train"><a href="#第六讲-大语言模型修炼史-第一阶段-Pre-train" class="headerlink" title="第六讲 大语言模型修炼史 第一阶段 Pre-train"></a>第六讲 大语言模型修炼史 第一阶段 Pre-train</h1><p>找最佳参数:</p>
<p><img src="/../img/generative-ai-find-best-parameters.png" srcset="/img/loading.gif" lazyload></p>
<p>但我们一般讲的调参数指的是调超参数. 除此之外, 还需要设置初始参数.</p>
<p>Explainable ML 分两类:</p>
<ul>
<li>Local explaination, 如 Why do you this this image is a cat?</li>
<li>Global explaination, 如 What does a “cat” look like?</li>
</ul>
<p>将高维降到低维进行观察:</p>
<p><img src="/../img/generative-ai-one-way-to-explain-result.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="Saliency-Map"><a href="#Saliency-Map" class="headerlink" title="Saliency Map"></a>Saliency Map</h2><h2 id="Integrated-Gradient"><a href="#Integrated-Gradient" class="headerlink" title="Integrated Gradient"></a>Integrated Gradient</h2><h2 id="Probing"><a href="#Probing" class="headerlink" title="Probing"></a>Probing</h2><h2 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h2><h1 id="第七讲-大语言模型修炼史-第二阶段-Instruction-Fine-tuning"><a href="#第七讲-大语言模型修炼史-第二阶段-Instruction-Fine-tuning" class="headerlink" title="第七讲 大语言模型修炼史 第二阶段 Instruction Fine-tuning"></a>第七讲 大语言模型修炼史 第二阶段 Instruction Fine-tuning</h1><p><img src="/../img/generative-ai-second-steps-example.png" srcset="/img/loading.gif" lazyload></p>
<p>使用 adapter 的 optimization 过程: 初始参数不变, 添加少量新参数:</p>
<p><img src="/../img/generative-ai-how-adapter-works.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>随参数插入的位置, 数目不同, 有各种 adapter 可用, 比如 LoRA</li>
</ul>
<h1 id="第八讲-大语言模型修炼史-第三阶段-RLHF"><a href="#第八讲-大语言模型修炼史-第三阶段-RLHF" class="headerlink" title="第八讲 大语言模型修炼史 第三阶段 RLHF"></a>第八讲 大语言模型修炼史 第三阶段 RLHF</h1><p>需要借助 Reinforcement Learning from Human Feedback, RLHF.</p>
<p>回顾一下三个阶段:</p>
<p><img src="/../img/generative-ai-re-look-three-stages.png" srcset="/img/loading.gif" lazyload></p>
<p>Instruction fine-tuning 和 RLHF 的比较:</p>
<p><img src="/../img/generative-ai-instruction-fine-tuning-vs-rlhf.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>Instruction fine-tuning 需要人类自己给出正确答案</li>
<li>RLHF 阶段只需要判断</li>
</ul>
<p>如何训练一个 reward model:</p>
<p><img src="/../img/generative-ai-train-a-reward-model.png" srcset="/img/loading.gif" lazyload></p>
<p>在增强式学习中, 可以从多个方面评价 “好坏”, 比如:</p>
<p><img src="/../img/generative-ai-rl-what-is-good.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>从 Safety 层面看该回答是好的</li>
<li>从 Helpfulness 层面看该回答是差的</li>
</ul>
<h1 id="第九讲-基于-LLM-的-AI-Agent"><a href="#第九讲-基于-LLM-的-AI-Agent" class="headerlink" title="第九讲 基于 LLM 的 AI Agent"></a>第九讲 基于 LLM 的 AI Agent</h1><p>AI Agent 可能的运作模式:</p>
<p><img src="/../img/generative-ai-agent-possible-work.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="第十讲-Transformer-简介"><a href="#第十讲-Transformer-简介" class="headerlink" title="第十讲 Transformer 简介"></a>第十讲 Transformer 简介</h1><p>当今大部分语言模型背后的都是 Transformer 这个类神经网络.</p>
<p>模型演进:</p>
<p><img src="/../img/generative-ai-modle-dev.png" srcset="/img/loading.gif" lazyload></p>
<p>Transformer 的工作流程:</p>
<p><img src="/../img/generative-ai-how-language-model-work-flow.png" srcset="/img/loading.gif" lazyload></p>
<p>语言模型是以 Token 作为单位来对文字进行处理, 因此要对输入进行切分, 如何切分则需要先构建一个 Token list (里面包含语言处理的基本单位, 也就是 token 的集合)</p>
<p><img src="/../img/generative-ai-how-tokenization-work.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>这里的 BPE 是一种自动发现 token list 的技术</li>
<li>每个语言模型定义的 token 不同, 可以在 <a target="_blank" rel="noopener" href="https://platform.openai.com/tokenizer">platform.openai.com&#x2F;tokenizer</a> 处查看 chatgpt 的 token</li>
</ul>
<p>在拆分为 token 后, 需要理解每个 token 的含义, 此时将其转化为 vector, 用向量的各维度表明含义, 这个过程也称为 embedding, 需要保证意思相近的 token 会有接近的 embedding:</p>
<p><img src="/../img/generative-ai-how-embedding-works.png" srcset="/img/loading.gif" lazyload></p>
<p>因此也需要存储一个 “token -&gt; embedding” 的列表进行映射.</p>
<ul>
<li>token embedding 的具体值也是模型参数的一部分, 可以在训练过程中得到</li>
<li>此时并没有考虑上下文</li>
</ul>
<p>除了语义, 还需要了解到 token 所在的位置, 一个做法就是为每一个位置都设定一个向量 (positional embedding, 可以人工设计, 也能训练获得), 然后与语义向量相加:</p>
<p><img src="/../img/generative-ai-how-position-works.png" srcset="/img/loading.gif" lazyload></p>
<p>一个 token 在不同的语境 (上下文) 有不同的含义, 比如 “果”:</p>
<ul>
<li>来吃苹果</li>
<li>苹果电脑</li>
</ul>
<p>显然需要用不同的 vector 来表示, 因此需要让 vector 通过 <code>Attention</code> 来考虑上下文 (变成 contextualized token embedding):</p>
<p><img src="/../img/generative-ai-why-attention-is-all-you-need.png" srcset="/img/loading.gif" lazyload></p>
<p>这里需要介绍 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> 这篇论文:</p>
<ul>
<li>其并不是 Attention 的发明者</li>
<li>Attention 早期需要配合 Recurrent Neural Network 使用</li>
<li>该论文主要贡献是发现不需要 RNN, 只需要 Attention 就够了</li>
</ul>
<p>简单来说, Attention 的作用是: 输入一排向量, 输出一排相同长度的向量, 但是加上了上下文的 embedding.</p>
<p><img src="/../img/generative-ai-attention-example1.png" srcset="/img/loading.gif" lazyload></p>
<p>需要计算与其他 token 的相关性:</p>
<p><img src="/../img/generative-ai-attention-calculate-relation.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/../img/generative-ai-attention-weight-comes.png" srcset="/img/loading.gif" lazyload></p>
<p>各 token embedding 通过与 attention weight 相乘得到输出:</p>
<p><img src="/../img/generative-ai-attention-output.png" srcset="/img/loading.gif" lazyload></p>
<p>所有这些相关性计算得到的 attention weight 组合成 attention matrix:</p>
<p><img src="/../img/generative-ai-attention-matrix-example.png" srcset="/img/loading.gif" lazyload></p>
<p>很多时候需要考虑 multi-head attention, 即关联性不只一种, 需要多种计算关联性的方法:</p>
<p><img src="/../img/generative-ai-multi-head-attention.png" srcset="/img/loading.gif" lazyload><br>(比如这里蓝色是一种计算方式, 黄色是另一种, 通常只计算左侧 token 的 attention weight)</p>
<p><img src="/../img/generative-ai-multi-head-attention-output.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>有多组输出</li>
</ul>
<p>之后通过 feed forward 来处理成一组输出:</p>
<p><img src="/../img/generative-ai-add-feed-forward-layer.png" srcset="/img/loading.gif" lazyload></p>
<p>“attention + feed forward” 组成一个 transformer block:</p>
<p><img src="/../img/generative-ai-transformer-block-example.png" srcset="/img/loading.gif" lazyload></p>
<p>通常需要多个 block, 最后通过 output layer 得到一个几率分布, 然后通过掷色子得到输出的 token:</p>
<p><img src="/../img/generative-ai-transformer-output.png" srcset="/img/loading.gif" lazyload></p>
<p>一些与 attention 相关的研究:</p>
<p><img src="/../img/generative-ai-attention-related-papers.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="第十一讲-大语言模型的可解释性"><a href="#第十一讲-大语言模型的可解释性" class="headerlink" title="第十一讲 大语言模型的可解释性"></a>第十一讲 大语言模型的可解释性</h1><p>通过模型结构解释, 或者分析模型的输出.</p>
<p>模型的结构很多时候难以解释, 但如何做出更好的决策是能够观察的.</p>
<p>比如找出一个影响输出的关键输入, 关键训练 data 等.</p>
<p><img src="/../img/generative-ai-larger-model-have-ability-to-learn-mul.png" srcset="/img/loading.gif" lazyload></p>
<p>还能够分析 embedding 中存储的信息:</p>
<p><img src="/../img/generative-ai-analyze-embedding.png" srcset="/img/loading.gif" lazyload></p>
<p>(probing 的技术)</p>
<p>投影到二维平面 (有很多种投影方式, 不只一种二维平面) 观察:</p>
<p><img src="/../img/generative-ai-convert-embedding-to-two-dimension.png" srcset="/img/loading.gif" lazyload></p>
<p>判断语言模型输出的真假:</p>
<p><img src="/../img/generative-ai-is-correct-ai-output.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="Transformer-延伸-1"><a href="#Transformer-延伸-1" class="headerlink" title="Transformer 延伸 1"></a>Transformer 延伸 1</h2><p>Transformer 是一个 Sequence-to-Sequence 的模型.</p>
<ul>
<li>输入一个 sequence, 输出也是 sequence, 但是长度由 model 决定</li>
</ul>
<p>很多 NLP 的问题都可以用 QA 的方式来训练, 而 QA 可以用 seq2seq 的方式解决.</p>
<p><img src="/../img/generative-ai-seq2seq-example.png" srcset="/img/loading.gif" lazyload></p>
<p>几个问题定义:</p>
<ul>
<li>Multi-class classification 指输入包含多个 classes 的数据</li>
<li>Multi-label classification 指输入的每个数据可以属于多个 classes</li>
</ul>
<p>Seq2seq 模型的结构:</p>
<p><img src="/../img/generative-ai-seq2seq-model-structure.png" srcset="/img/loading.gif" lazyload></p>
<p>Encode 的结构:</p>
<p><img src="/../img/generative-ai-encoder-structure.png" srcset="/img/loading.gif" lazyload></p>
<p>Residual 的结构, 输出加上输入等于最终输出:</p>
<p><img src="/../img/generative-ai-residual-structure-example.png" srcset="/img/loading.gif" lazyload></p>
<p>Decoder 一般分两种:</p>
<ul>
<li>Autoregressive</li>
<li>Non-autoregressive</li>
</ul>
<p>这里以 Autoregressive 为例.</p>
<p>Decoder 处理开始:</p>
<p><img src="/../img/generative-ai-decoder-process-begin.png" srcset="/img/loading.gif" lazyload></p>
<p>Decoder 处理结束:</p>
<p><img src="/../img/generative-ai-decoder-end-process.png" srcset="/img/loading.gif" lazyload></p>
<p>Decoder 的内部结构:</p>
<p><img src="/../img/generative-ai-decoder-structure-example.png" srcset="/img/loading.gif" lazyload></p>
<p>Self-attention 会考虑全部的输入:</p>
<p><img src="/../img/generative-ai-self-attention-example.png" srcset="/img/loading.gif" lazyload></p>
<p>而 Masked self-attention 指不考虑当前输入后续的输入:</p>
<p><img src="/../img/generative-ai-masked-self-attention-example.png" srcset="/img/loading.gif" lazyload></p>
<p>Autoregressive vs Non-autoregressive:</p>
<p><img src="/../img/generative-ai-nat-vs-at-example.png" srcset="/img/loading.gif" lazyload></p>
<p>Encoder 与 Decoder 的连接:</p>
<p><img src="/../img/generative-ai-how-encoder-connect-to-decoder.png" srcset="/img/loading.gif" lazyload></p>
<p>具体计算过程:</p>
<p><img src="/../img/generative-ai-cross-attention-detail.png" srcset="/img/loading.gif" lazyload></p>
<p>训练过程:</p>
<p><img src="/../img/generative-ai-train-transformer-example.png" srcset="/img/loading.gif" lazyload></p>
<p>在 Decoder 输入处给出正确答案.</p>
<p>Scheduled sampling, 在训练输入中提供一些错误:</p>
<p><img src="/../img/generative-ai-scheduled-sampling-example.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="第十二讲-评判语言模型的能力"><a href="#第十二讲-评判语言模型的能力" class="headerlink" title="第十二讲 评判语言模型的能力"></a>第十二讲 评判语言模型的能力</h1><p>基本评判模式:</p>
<p><img src="/../img/generative-ai-what-is-benchmark.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>Benchmark 就是预先准备好的标准输入和输出</li>
</ul>
<p>但很多问题没有标准答案, 因此评判起来比较困难, 但也有一些知名的方法:</p>
<ul>
<li>翻译问题, 用 BLEU 评比</li>
<li>摘要问题, 用 ROUGE 评比</li>
</ul>
<p>也可以用强大的语言模型来代替人进行评估.</p>
<p>网络上目前有各式各样的 Benchmark 可用.</p>
<h1 id="第十七讲-与影像相关的生成式-AI-上"><a href="#第十七讲-与影像相关的生成式-AI-上" class="headerlink" title="第十七讲 与影像相关的生成式 AI 上"></a>第十七讲 与影像相关的生成式 AI 上</h1><p>一般来说有两种:</p>
<p><img src="/../img/generative-ai-with-image-and-video.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>通过 video&#x2F;image 来生成其他内容, 比如文本</li>
<li>通过文本等生成 video&#x2F;image, 比如 Sora (也可以用图片生成图片, video 生成 video)</li>
</ul>
<p>几个相关单位:</p>
<ul>
<li>Pixel</li>
</ul>
<p><img src="/../img/generative-ai-frame-compose-image.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>Frame</li>
</ul>
<p><img src="/../img/generative-ai-video-compose-of-frame.png" srcset="/img/loading.gif" lazyload></p>
<p>当今 generative ai 并不是一个 pixel 一个 pixel 来处理图片, 而是归功于一些图片压缩的技术, 图片先进入 Encoder 处理, 将图片切割成 patch, 最后通过 Decoder 来生成:</p>
<p><img src="/../img/generative-ai-how-ai-saw-image.png" srcset="/img/loading.gif" lazyload></p>
<p>对于 video, 将每一个 frame 都经过 encoder 处理:</p>
<p><img src="/../img/generative-ai-how-to-deal-video.png" srcset="/img/loading.gif" lazyload></p>
<p>常见用于训练文字生图的数据集: <a target="_blank" rel="noopener" href="https://laion.ai/blog/laion-5b">https://laion.ai/blog/laion-5b</a></p>
<p>评判影像生成的好坏可以用 CLIP 模型.</p>
<h1 id="第十八讲-与影像相关的生成式-AI-下"><a href="#第十八讲-与影像相关的生成式-AI-下" class="headerlink" title="第十八讲 与影像相关的生成式 AI 下"></a>第十八讲 与影像相关的生成式 AI 下</h1><p>常见的影像生成的方法有:</p>
<ul>
<li>Variational Auto-encoder</li>
<li>Flow-based Method</li>
<li>Diffusion Method</li>
<li>Generative Adversarial Network</li>
</ul>
<p>图像生成常见的问题:</p>
<p><img src="/../img/generative-ai-common-problem-for-image.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>训练文生图模型时, 一个文本可能对应多个图片, 生成时如何选择</li>
</ul>
<p>一个方法是, 训练一个模型抽取出文本没有描述出的内容:</p>
<p><img src="/../img/generative-ai-extract-info-from-image.png" srcset="/img/loading.gif" lazyload></p>
<p>这也是 VAE 和 Flow-based 方法的处理思路:</p>
<p><img src="/../img/generative-ai-vae-and-flow-based-method.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>中间的 Noise 其实包含很多特征信息</li>
</ul>
<p>Diffusion Model 只借助一个 decoder, 通过重复 denoise 操作来得到最终图片:</p>
<p><img src="/../img/generative-ai-diffusion-model-example.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>相关的研究集中在以更少的 denoise 操作生成最终图片, denoise 可以是 transformer 模型</li>
</ul>
<p>Diffusion model 的训练过程则是通过向原始图片添加 noise:</p>
<p><img src="/../img/generative-ai-how-to-train-diffusion-model.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/../img/generative-ai-diffusion-process.png" srcset="/img/loading.gif" lazyload></p>
<p>Generative Adversarial Network 的训练方法:</p>
<p><img src="/../img/generative-ai-gan-method-example.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>GAN 能很容易与其他方法结合</li>
</ul>
<p><img src="/../img/generative-ai-gan-with-other-method.png" srcset="/img/loading.gif" lazyload></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/AI/" class="category-chain-item">AI</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Generative-AI-导论</div>
      <div>http://example.com/2025/08/05/Generative-AI-导论/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Jie</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年8月5日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/08/11/Transformer-%E6%9E%B6%E6%9E%84/" title="Transformer-架构">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Transformer-架构</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/08/04/Pytorch-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/" title="Pytorch-基本使用">
                        <span class="hidden-mobile">Pytorch-基本使用</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'zKurisu/comments-utterances');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Jie</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Orkarin</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
