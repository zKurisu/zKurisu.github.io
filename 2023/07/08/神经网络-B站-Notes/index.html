

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/wallhaven-j5kjgy_1920x1080.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="介绍机器学习流程:  数据获取 特征工程 建立模型 评估与应用  深度学习极大地加快特征工程的完成. 特征工程的作用:  数据特征决定了模型的上限 预处理和特征提取是最核心的 算法与参数选择决定了如何逼近这个上限  将深度学习当作黑盒子来学习比较容易.  神经网络这个黑盒能够对输入进行 特征提取(各种特征), 从而让计算机认识, 计算机会选择哪些特征是最合适的. 因此深度学习解决的就是如何提取特征">
<meta property="og:type" content="article">
<meta property="og:title" content="神经网络-B站-Notes">
<meta property="og:url" content="http://example.com/2023/07/08/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-B%E7%AB%99-Notes/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="介绍机器学习流程:  数据获取 特征工程 建立模型 评估与应用  深度学习极大地加快特征工程的完成. 特征工程的作用:  数据特征决定了模型的上限 预处理和特征提取是最核心的 算法与参数选择决定了如何逼近这个上限  将深度学习当作黑盒子来学习比较容易.  神经网络这个黑盒能够对输入进行 特征提取(各种特征), 从而让计算机认识, 计算机会选择哪些特征是最合适的. 因此深度学习解决的就是如何提取特征">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/k-nearest-neighbor-algorithm.png">
<meta property="og:image" content="http://example.com/img/a-pic-for-net.png">
<meta property="og:image" content="http://example.com/img/a-3072-pixel-example.png">
<meta property="og:image" content="http://example.com/img/gain-point-function-example.png">
<meta property="og:image" content="http://example.com/img/how-to-get-weight-element.png">
<meta property="og:image" content="http://example.com/img/decide-edge.png">
<meta property="og:image" content="http://example.com/img/example-of-lose-score-function.png">
<meta property="og:image" content="http://example.com/img/forward-propagation.png">
<meta property="og:image" content="http://example.com/img/transfer-scores-to-pro.png">
<meta property="og:image" content="http://example.com/img/real-clarify-of-nn.png">
<meta property="og:image" content="http://example.com/img/change-the-input.png">
<meta property="og:image" content="http://example.com/img/reverse-propagation.png">
<meta property="og:image" content="http://example.com/img/how-reverse-propagation-works.png">
<meta property="og:image" content="http://example.com/img/gate-unit-of-reversee-propagation.png">
<meta property="og:image" content="http://example.com/img/stricture-of-neural-network.png">
<meta property="og:image" content="http://example.com/img/convert-process-of-neureul.png">
<meta property="og:image" content="http://example.com/img/unlinear-after-the-matrix-varies.png">
<meta property="og:image" content="http://example.com/img/how-punish-power-affects.png">
<meta property="og:image" content="http://example.com/img/comparison-of-two-activation-function.png">
<meta property="og:image" content="http://example.com/img/preprocessing-of-data-for-nutrul-network.png">
<meta property="og:image" content="http://example.com/img/how-drop-out-work.png">
<meta property="og:image" content="http://example.com/img/diff-between-nn-and-cnn.png">
<meta property="og:image" content="http://example.com/img/whole-structure-of-cnn.png">
<meta property="og:image" content="http://example.com/img/grab-charac-from-a-pic.png">
<meta property="og:image" content="http://example.com/img/rgb-three-color-channel.png">
<meta property="og:image" content="http://example.com/img/an-example-of-cnn.png">
<meta property="og:image" content="http://example.com/img/featuar-map.png">
<meta property="og:image" content="http://example.com/img/six-featuar-maps.png">
<meta property="og:image" content="http://example.com/img/mul-cnn.png">
<meta property="og:image" content="http://example.com/img/diff-steps.png">
<meta property="og:image" content="http://example.com/img/margin-pading-one.png">
<meta property="og:image" content="http://example.com/img/share-the-core-of-cnn.png">
<meta property="og:image" content="http://example.com/img/pooling-layer.png">
<meta property="og:image" content="http://example.com/img/max-pooling.png">
<meta property="og:image" content="http://example.com/img/whole-structure-of-CNN.png">
<meta property="og:image" content="http://example.com/img/changing-of-charac-map.png">
<meta property="og:image" content="http://example.com/img/recurrent-neural-network.png">
<meta property="article:published_time" content="2023-07-08T07:41:31.000Z">
<meta property="article:modified_time" content="2023-07-10T09:12:26.245Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/k-nearest-neighbor-algorithm.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>神经网络-B站-Notes - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  



  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Jie</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/SteinsGate_all.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="神经网络-B站-Notes"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-07-08 15:41" pubdate>
          2023年7月8日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          7.2k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          61 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">神经网络-B站-Notes</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>机器学习流程:</p>
<ul>
<li>数据获取</li>
<li>特征工程</li>
<li>建立模型</li>
<li>评估与应用</li>
</ul>
<p>深度学习极大地加快特征工程的完成.</p>
<p>特征工程的作用:</p>
<ul>
<li>数据特征决定了模型的上限</li>
<li>预处理和特征提取是最核心的</li>
<li>算法与参数选择决定了如何逼近这个上限</li>
</ul>
<p>将深度学习当作黑盒子来学习比较容易. </p>
<p>神经网络这个黑盒能够对输入进行 <mark>特征提取</mark>(各种特征), 从而让计算机认识, 计算机会选择哪些特征是最合适的.</p>
<p>因此深度学习解决的就是如何提取特征.</p>
<p>应用, 主要在计算机视觉和自然语言处理方面:</p>
<ul>
<li>检测和识别, 如人脸, 车辆</li>
</ul>
<p>深度学习的一个缺点: 计算量大. 因此在移动端的普及还比较缓慢.</p>
<p>深度学习在医学方面的应用: 基因组合, 癌细胞检测等.</p>
<ul>
<li>换脸</li>
<li>分辨率重构</li>
</ul>
<p>(有监督问题, 指有分类和标签的输入)</p>
<p>在数据规模较小时, 用 <mark>传统的人工智能算法</mark> 即可, 只有当数据规模极大时, 才考虑 <mark>深度学习</mark> 算法.</p>
<p>对于提高数据量 – 将输入数据, 如一张图片进行翻转等操作, 相当于得到另一个数据.</p>
<blockquote>
<p>计算机视觉上的示例</p>
</blockquote>
<p>在计算机中, 一张图片被表示成三维数组的形式, 每个像素被表示成三维数组的形式, 每个像素的值从 0 到 255. 数值越低表明其越暗, 越高则越亮.</p>
<p>注意 <mark>颜色通道</mark> 的概念. 如 <code>RGB</code> 表示 Red, Green, Blue 的 3 颜色通道.</p>
<p>如:</p>
<figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">300 </span>x <span class="hljs-number">100</span> x <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure>
<p>这里的 3 表示的就是 3 颜色通道.</p>
<p>计算机识别遇到的困难有: </p>
<ul>
<li>部分遮蔽</li>
<li>背景混入</li>
</ul>
<p>需解决这些问题, 还是需要数据量 (带标签).</p>
<blockquote>
<p>机器学习常规套路</p>
</blockquote>
<ol>
<li>收集数据并给定标签</li>
<li>训练一个分类器</li>
<li>测试, 评估</li>
</ol>
<blockquote>
<p>K 近邻算法</p>
</blockquote>
<p><img src="/../img/k-nearest-neighbor-algorithm.png" srcset="/img/loading.gif" lazyload></p>
<p>计算流程:</p>
<ol>
<li>计算已知类别数据集中的点与当前点的距离</li>
<li>按照距离一次排序</li>
<li>选取与当前点距离最小的 K 个点</li>
<li>确定前 K 个点所在类别的出现概率</li>
<li>返回前 K 个点出现频率最高的类别作为当前点预测分类</li>
</ol>
<blockquote>
<p>可自己利用的数据集</p>
</blockquote>
<p>CIFAR-10</p>
<p>特点:</p>
<ul>
<li>10 类标签</li>
<li>50000 个训练数据</li>
<li>10000 个测试数据  </li>
<li>大小均为 32 * 32</li>
</ul>
<h1 id="2-得分函数"><a href="#2-得分函数" class="headerlink" title="2 得分函数"></a>2 得分函数</h1><p>也就是一个 <mark>线性函数</mark>.</p>
<p>每一个特征都对应一个权重参数.</p>
<p><img src="/../img/a-pic-for-net.png" srcset="/img/loading.gif" lazyload></p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>f(x,W) &#x3D; Wx + b<br>\end{aligned}<br>}<br>$$<br>( <code>x</code> 指代像素点, <code>W</code> 指代权重参数, <code>b</code> 是偏置参数, 这里的 <code>W</code>, <code>x</code>, <code>b</code> 都是矩阵 )</p>
<p>权重参数和偏置参数:</p>
<ul>
<li>权重参数起决定性因素</li>
<li>偏置参数起微调的作用</li>
</ul>
<p>如上面的例子, 由于有 $32 \times 32 \times 3 &#x3D; 3072$ 个像素点, 因此有 $3072$ 个权重参数, 也就是说:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>W &#x3D; 某矩阵 (1 \times 3072 的矩阵)<br>\end{aligned}<br>}<br>$$</p>
<p>而所有的像素点可以表示为:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>x &#x3D; 某矩阵 ( 3072 \times 1 的矩阵 )<br>\end{aligned}<br>}<br>$$</p>
<p>对于不同的类别, 可以得到不同的 W 矩阵, 如类别猫对应 $W_1$, 类别狗对应 $W_2$…</p>
<p>通过:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>f(x,W) &#x3D; W_n x + b<br>\end{aligned}<br>}<br>$$</p>
<p>来得到不同类别的得分:</p>
<p><img src="/../img/a-3072-pixel-example.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/../img/gain-point-function-example.png" srcset="/img/loading.gif" lazyload></p>
<p>权重参数中, 值比较大的位表示与其相乘的像素点对于这个特征比较重要. 且正值代表促进, 负值代表抑制.</p>
<blockquote>
<p>权重参数矩阵如何得来</p>
</blockquote>
<p>以这里举例.</p>
<p>先随机构造一个 $3 \times 4$ 的矩阵.</p>
<p><img src="/../img/how-to-get-weight-element.png" srcset="/img/loading.gif" lazyload></p>
<p>由于输入 (这里指图片) 是不变的, 可以通过优化 (调整) W 矩阵来使结果符合预期 (如这里应该判断为猫, 即猫的 score 应该最高)</p>
<p>而神经网络的周期 (迭代) 过程中, 就是不断优化 W 矩阵, 来满足对数据的判断.</p>
<blockquote>
<p>决策边界</p>
</blockquote>
<p><img src="/../img/decide-edge.png" srcset="/img/loading.gif" lazyload></p>
<p><mark>决策边界</mark> , 大概就是判断输入属于什么类别的临界值.</p>
<p><code>W</code> 对这个临界值起决定作用.</p>
<h1 id="3-损失函数"><a href="#3-损失函数" class="headerlink" title="3 损失函数"></a>3 损失函数</h1><p>如何定义损失函数, 会改变神经网络是做分类还是回归之类的.</p>
<p>损失函数相当于一个指导模型, 来告诉神经网络当前的得分是好是坏, 从而改进.</p>
<p>如:</p>
<p><img src="/../img/example-of-lose-score-function.png" srcset="/img/loading.gif" lazyload></p>
<p>(这里有各个类别对应的得分)</p>
<p>损失函数需要在得到一个结果后再对其进行评估.</p>
<p>损失函数的结果应该越低越好, 如:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>L_i &#x3D; \sum_{j \ne y_i} max(0, s_j - s_{y_i} + 1)<br>\end{aligned}<br>}<br>$$<br>( $L_i$ 就是 loss 值 )</p>
<p>$s_j$ 表示错误类别的得分.</p>
<p>$s_{y_i}$ 表示正确类别的得分.</p>
<p>$\sum$ 表示每个错误类型都需要计算.</p>
<p>$+1$ 表示容忍程度, 应该是可以变的. 这里表示损失函数只要小于 1 就能接受.</p>
<p>损失函数的值为 0 时表示没有损失.</p>
<p>可以看出, 损失函数是用来评估得分函数得到的结果.</p>
<p>需注意, <mark>损失函数的值相同, 并不能代表两个模型一样</mark> </p>
<p>在训练网络模型的过程中, 最好是使模型趋于稳定, 如两个模型:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>模型A:\omega_1 &#x3D; [1,0,0,0] \newline~ \newline<br>模型B:\omega_2 &#x3D; [0.25,0.25,0.25,0.25]<br>\end{aligned}<br>}<br>$$</p>
<p>这里的模型 B 就更稳定.</p>
<blockquote>
<p>一般的损失函数的定义</p>
</blockquote>
<figure class="highlight fix"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs fix"><span class="hljs-attr">损失函数 </span>=<span class="hljs-string"> 数据损失 + 正则化惩罚项</span><br></code></pre></td></tr></table></figure>

<p>这里的 “正则化惩罚项” 作用于数据中的 “变异项”, 用于削减 “变异项” 对数据拟合的影响:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>L &#x3D; \frac{1}{N} \sum_{i &#x3D; 1}^N \sum_{j \ne y_i} max(0,f(x_i, W)_j - f(x_i, W)_{y_i} + 1) + \lambda R(W) \newline~ \newline<br>R(W) &#x3D; \sum_k \sum_l W^2_{k,l}<br>\end{aligned}<br>}<br>$$</p>
<p>这里的 $\lambda R(W)$ 就是正则惩罚项. 其和数据没关系, 只和权重参数相关. $\lambda$ 是惩罚系数. $\lambda$ 比较大表明要 “杀死变异项”, 比较小则表明 “削弱变异项”.</p>
<h1 id="4-向前传播整体流程"><a href="#4-向前传播整体流程" class="headerlink" title="4 向前传播整体流程"></a>4 向前传播整体流程</h1><p><img src="/../img/forward-propagation.png" srcset="/img/loading.gif" lazyload></p>
<p>可以看出这是一个反馈模型.</p>
<blockquote>
<p>如何将得分值转化成一u个概率值</p>
</blockquote>
<p>用一个函数, 如:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>g(z) &#x3D; \frac{1}{1 + e^{-z}}<br>\end{aligned}<br>}<br>$$</p>
<p><img src="/../img/transfer-scores-to-pro.png" srcset="/img/loading.gif" lazyload></p>
<p>这个函数的特点就是其值的范围是 $[0,1]$.</p>
<blockquote>
<p>实际神经网络的分类</p>
</blockquote>
<p><img src="/../img/real-clarify-of-nn.png" srcset="/img/loading.gif" lazyload></p>
<p>一个输入, 通过得分函数得到一个 scores, 将 scores 做放大处理 (放大差异), 最后进行归一化处理 (总概率唯一).</p>
<p>归一化指:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>\frac{24.5}{24.5 + 164.0 + 0.18}  &#x3D; 0.13 \newline~ \newline<br>\frac{164.0}{24.5 + 164.0 + 0.18} &#x3D; 0.87 \newline~ \newline<br>\frac{-1.7}{24.5 + 164.0 + 0.18}  &#x3D; 0.00 \newline~ \newline<br>\end{aligned}<br>}<br>$$</p>
<p>实际公式为:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>P(Y &#x3D; k | X &#x3D; x_i) &#x3D; \frac{e^s k}{e^s j}, s &#x3D; f(x_i, W)<br>\end{aligned}<br>}<br>$$<br>( 分子分母中的 $e^s$ 就是放大的步骤 )</p>
<p>这里只需关心正确类别的概率值 (这里是 cat, 概率为 0.13)</p>
<p>通过这个概率来计算损失, 计算公式为:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>L_i &#x3D; -log P(Y&#x3D;y_i | X &#x3D; x_i) \newline~ \newline<br>L_i &#x3D; -log(0.13) &#x3D; 0.89<br>\end{aligned}<br>}<br>$$</p>
<p>回归任务, 用得分值计算损失.</p>
<p>分类任务, 用概率值计算损失.</p>
<p>神经网络分为两个模块:</p>
<ul>
<li>前向传播, 数据输入, 得到损失</li>
<li>反向传播</li>
</ul>
<h1 id="5-反向传播"><a href="#5-反向传播" class="headerlink" title="5 反向传播"></a>5 反向传播</h1><p><img src="/../img/change-the-input.png" srcset="/img/loading.gif" lazyload></p>
<p>这里的 A, B, C 代表不同的改变得到不同的输入, 也就是不同的侧重点.</p>
<p><img src="/../img/reverse-propagation.png" srcset="/img/loading.gif" lazyload></p>
<p>注意偏导的求法.</p>
<p>逐层, 按顺序, 从后往前.</p>
<blockquote>
<p>定义</p>
</blockquote>
<p>反向传播（Backpropagation）是一种用于训练神经网络的算法。它通过计算网络的输出误差，然后将误差反向传播回网络中的每个神经元，以更新它们的权重和偏置，从而提高网络的性能。</p>
<p><img src="/../img/how-reverse-propagation-works.png" srcset="/img/loading.gif" lazyload></p>
<p>也就是说, 先通过正向传播得到一个 loss 值, 用这个 loss 值一个一个往回更新权重和偏置的值.</p>
<blockquote>
<p>梯度下降算法</p>
</blockquote>
<p>梯度下降算法是一种常用的优化算法，也是神经网络中最基本的优化算法之一。它的作用是通过计算损失函数关于权重和偏置的梯度，来更新网络的参数，从而使损失函数最小化。</p>
<p>在神经网络中，我们通常使用反向传播算法来计算损失函数关于权重和偏置的梯度。然后，通过梯度下降算法来更新权重和偏置，从而最小化损失函数。</p>
<blockquote>
<p>梯度</p>
</blockquote>
<p>梯度是一个向量，它表示某个多元函数在某一点的变化率。在数学上，梯度是一个向量，其方向指向函数值增加最快的方向，大小表示函数值增加的速率</p>
<p>当提到让网络学习, 实质上就是让代价函数的值最小.</p>
<p>梯度的另一个理解, 如一个函数的梯度为:<br>$$<br>\displaylines<br>{<br>\begin{aligned}<br>\begin{bmatrix}<br>    3 \<br>    1<br>\end{bmatrix}<br>\end{aligned}<br>}<br>$$</p>
<p>可以理解为沿向量 $(3,1)$ 方向函数增加得最快, 也可以理解为函数的第一个参数的重要性是第二个参数的 3 倍.</p>
<p>这里用梯度下降, 就是为了让代价最小.</p>
<blockquote>
<p>门单元</p>
</blockquote>
<p>反向传播中的 3 中门单元:</p>
<ul>
<li>加法门单元: 均等分配</li>
<li>MAX 门单元: 给最大的</li>
<li>乘法门单元: 互换</li>
</ul>
<p><img src="/../img/gate-unit-of-reversee-propagation.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="6-神经网络的整体架构"><a href="#6-神经网络的整体架构" class="headerlink" title="6 神经网络的整体架构"></a>6 神经网络的整体架构</h1><p>整体架构图如下:</p>
<p><img src="/../img/stricture-of-neural-network.png" srcset="/img/loading.gif" lazyload></p>
<p>神经网络是一层一层进行处理的.</p>
<p>隐层其实就是对原始数据 (input layer) 做变换得到的.</p>
<p>hiden layer 的结果不一定是一个有意义的值.<br>变换过程如:</p>
<p><img src="/../img/convert-process-of-neureul.png" srcset="/img/loading.gif" lazyload></p>
<p>可以看出, 这里最重要的就是选择合适的 $W_1$, $W_2$ 和 $W_3$, 也就是权重参数.</p>
<p>注意每一次矩阵变换之后都会有 <mark>非线性变换</mark> , 如:</p>
<p><img src="/../img/unlinear-after-the-matrix-varies.png" srcset="/img/loading.gif" lazyload></p>
<p>基本的机构如:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>f &#x3D; W_2 max(0, W_1 x) \newline~ \newline<br>f &#x3D; W_3 max(0, W_2 max(0, W_1 x))<br>\end{aligned}<br>}<br>$$</p>
<p>网络中的神经元越多, 效果越好. 但是过拟合的风险越大.</p>
<h1 id="7-正则化与激活函数"><a href="#7-正则化与激活函数" class="headerlink" title="7 正则化与激活函数"></a>7 正则化与激活函数</h1><p>惩罚力度对结果的影响:</p>
<p><img src="/../img/how-punish-power-affects.png" srcset="/img/loading.gif" lazyload></p>
<p>可以看出, 惩罚力度越大, 越规整.</p>
<blockquote>
<p>激活函数</p>
</blockquote>
<p>激活函数给出了几种常见的非线性变换.</p>
<p>两种激活函数的对比:</p>
<p><img src="/../img/comparison-of-two-activation-function.png" srcset="/img/loading.gif" lazyload></p>
<p>sigmoid 函数的缺点在于可能会出现 <mark>梯度消失</mark> .</p>
<h1 id="8-数据预处理"><a href="#8-数据预处理" class="headerlink" title="8 数据预处理"></a>8 数据预处理</h1><p>得到数据之后, 不能直接将数据输入到神经网络中. 需要做一些预处理:</p>
<p><img src="/../img/preprocessing-of-data-for-nutrul-network.png" srcset="/img/loading.gif" lazyload></p>
<blockquote>
<p>参数初始化</p>
</blockquote>
<p>也就是随机得到权重参数矩阵.</p>
<h1 id="9-神经网络中过拟合解决方法"><a href="#9-神经网络中过拟合解决方法" class="headerlink" title="9 神经网络中过拟合解决方法"></a>9 神经网络中过拟合解决方法</h1><p>除了正则化 $R(w)$ 之外, 还可以利用 <mark>DROP-OUT</mark> 的思想.</p>
<p><img src="/../img/how-drop-out-work.png" srcset="/img/loading.gif" lazyload></p>
<p>在每一次迭代中, 每一层中随机舍弃几个神经元, 这样每一次迭代的复杂程度就会降低.</p>
<h1 id="10-卷积神经网络应用领域"><a href="#10-卷积神经网络应用领域" class="headerlink" title="10 卷积神经网络应用领域"></a>10 卷积神经网络应用领域</h1><p>Convolutional Neural Network, CNN.</p>
<p>主要用于计算机视觉方面. 分类与检索, 超分辨率重构, 细胞检测, 字体识别, 无人驾驶等功能.</p>
<h1 id="11-卷积的作用"><a href="#11-卷积的作用" class="headerlink" title="11 卷积的作用"></a>11 卷积的作用</h1><blockquote>
<p>卷积网络与传统网络的区别</p>
</blockquote>
<p><img src="/../img/diff-between-nn-and-cnn.png" srcset="/img/loading.gif" lazyload></p>
<p>传统网络的输入是一个向量 (由特征得来, 如将图像化为像素点).</p>
<p>卷积神经网络的输入是一个有长, 宽, 高的原始数据 (如图像本身)</p>
<p>整体架构包括:</p>
<ul>
<li>输入层</li>
<li>卷积层, 提取特征</li>
<li>池化层, 压缩特征</li>
<li>全连接层</li>
</ul>
<p><img src="/../img/whole-structure-of-cnn.png" srcset="/img/loading.gif" lazyload></p>
<p>卷积同样通过一组权重参数来提取特征, 如:</p>
<p><img src="/../img/grab-charac-from-a-pic.png" srcset="/img/loading.gif" lazyload></p>
<p>(最右侧的为特征图)</p>
<p>这里就是 3x3 提取出一个特征. 包含一组权重参数矩阵.</p>
<p>目的同样是用一组合理的权重参数矩阵, 使得结果最好.</p>
<h1 id="12-卷积特征值计算方法"><a href="#12-卷积特征值计算方法" class="headerlink" title="12 卷积特征值计算方法"></a>12 卷积特征值计算方法</h1><p>对于一个有 3 颜色通道的图片, 需要对每个通道分别计算, 然后加在一起:</p>
<p><img src="/../img/rgb-three-color-channel.png" srcset="/img/loading.gif" lazyload></p>
<p>一个示例:</p>
<p><img src="/../img/an-example-of-cnn.png" srcset="/img/loading.gif" lazyload></p>
<p>先看左上角的输入, $7 \times 7 \times 3$ 的含义为, 数据为 $7 \times 7$ 的矩阵, 有三个类别 (这里相当于 3 个通道, R, G, B)</p>
<p>特征提取, 则需要中间的 filter, 其中 $3 \times 3 \times 3$ 的含义为, 前两个 $3 \times 3$ 为卷积核 (就是中间的矩阵, 也就是用于选取特征的大小) 的大小, 后一个 3 需要和输入的第三维度相同 (也就是这里的通道数).</p>
<p>计算方法: 所有的卷积网中都通过内积做计算. 然后将各个类别的结果加在一起.</p>
<p>注意最后加上 $b$ 也就是 Bios 参数.</p>
<p>卷积的结果是得到特征图:</p>
<p><img src="/../img/featuar-map.png" srcset="/img/loading.gif" lazyload></p>
<p>即最右侧的绿色的图.</p>
<p>对同样的数据, 应用不同的 filter 可以得到不同的特征图.</p>
<p><img src="/../img/six-featuar-maps.png" srcset="/img/loading.gif" lazyload></p>
<p>在卷积过程中, 使用的多个核的规格应该相同.</p>
<h1 id="13-步长与卷积核大小对结果的影响"><a href="#13-步长与卷积核大小对结果的影响" class="headerlink" title="13 步长与卷积核大小对结果的影响"></a>13 步长与卷积核大小对结果的影响</h1><p>做一次卷积往往是不够的. 在得到特征图之后, 再对特征图做卷积.</p>
<p>如:</p>
<p><img src="/../img/mul-cnn.png" srcset="/img/loading.gif" lazyload></p>
<p>注意几个参数值:</p>
<ul>
<li>滑动窗口步长</li>
</ul>
<p><img src="/../img/diff-steps.png" srcset="/img/loading.gif" lazyload></p>
<p>也就是每次计算特征图所移动的单元格.</p>
<p>步长越小, 得到的特征图的规格越大. 也就是说, 粒度比较细, 特征比较丰富.</p>
<ul>
<li>卷积核尺寸, 也就是卷积核矩阵的大小, 一般为 $3 \times 3$</li>
<li>边缘填充, 一般为 zero pading, 填充 0 (不会因填充物而造成影响)</li>
</ul>
<p><img src="/../img/margin-pading-one.png" srcset="/img/loading.gif" lazyload><br>可以看到顶部写的 <code>*pad 1</code> 表示填充了 1 圈, 填充的原因是: 中间部分的数据被多次计算, 而边缘的数据计算次数少, 填充新的边界可以减缓这种影响</p>
<ul>
<li>卷积核个数, 决定了要得到多少个特征图</li>
</ul>
<h1 id="14-特征图尺寸计算与参数共享"><a href="#14-特征图尺寸计算与参数共享" class="headerlink" title="14 特征图尺寸计算与参数共享"></a>14 特征图尺寸计算与参数共享</h1><p>卷积结果计算公式:</p>
<p>$$<br>\displaylines<br>{<br>\begin{aligned}<br>长度:H_2 &#x3D; \frac{H_1 - F_H + 2P}{S} + 1 \newline~ \newline<br>宽度: W_2 &#x3D; \frac{W_1 - F_W + 2P}{S} + 1<br>\end{aligned}<br>}<br>$$<br>$W_1$ 和 $H_1$ 表示输入的宽度和长度.</p>
<p>$W_2$ 和 $H_2$ 表示输出特征图的宽度和长度.</p>
<p>$F_H$ 和 $F_W$ 表示卷积核的长度和宽度.</p>
<p>$S$ 表示滑动窗口的步长.</p>
<p>$P$ 表示边界填充 (加了多少圈 0).</p>
<blockquote>
<p>卷积参数共享 </p>
</blockquote>
<p>指可以用几个卷积核来完成对整个数据的卷积操作, 而不是每一个输入对应一个参数.</p>
<p><img src="/../img/share-the-core-of-cnn.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="15-池化层"><a href="#15-池化层" class="headerlink" title="15 池化层"></a>15 池化层</h1><p>池化层, 也可以称压缩, 下采样, 也就是减小采集的特征数量. 如:</p>
<p><img src="/../img/pooling-layer.png" srcset="/img/loading.gif" lazyload></p>
<p>一开始的数据为 $224 \times 224 \times 64$, 经过 pool 之后变为 $112 \times 112 \times 64$, 因此可提取出的特征数就减少了. </p>
<blockquote>
<p>Max Pooling</p>
</blockquote>
<p><img src="/../img/max-pooling.png" srcset="/img/loading.gif" lazyload></p>
<p>选择一个区域, 从区域内选择最大的数值提取出来, 如左上角的 $2 \times 2$ 的区域, $6$ 最大, 则被提取出.</p>
<p>另外也有 average pooling, 但效果没有 max pooling 好. </p>
<h1 id="16-整体网络架构"><a href="#16-整体网络架构" class="headerlink" title="16 整体网络架构"></a>16 整体网络架构</h1><p><img src="/../img/whole-structure-of-CNN.png" srcset="/img/loading.gif" lazyload></p>
<p>可以看到, 一般每两次卷积做一次 pooling, 而每次卷积之后, 都需要用激活函数 (如这里的 RELU 函数) 计算一次.</p>
<p>在最后一个 Pooling 层和 FC (Full Connect, 全连接层) 之间, 需要将得到的特征图先转换为一个长向量.</p>
<p>注意, 只有带参数的计算层才算作一层.</p>
<blockquote>
<p>特征图的变化过程</p>
</blockquote>
<p><img src="/../img/changing-of-charac-map.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="17-其他经典网络"><a href="#17-其他经典网络" class="headerlink" title="17 其他经典网络"></a>17 其他经典网络</h1><p>VGG 网络架构.</p>
<p>残差网络 Resnet – 增加网络层数, 训练出来的至少不比原来差. 将不需要的层数舍弃.</p>
<h1 id="18-感受野的作用"><a href="#18-感受野的作用" class="headerlink" title="18 感受野的作用"></a>18 感受野的作用</h1><p>“感受野” (receptive field) 越大越好.</p>
<p>感受野（receptive field）是指神经元对输入数据的响应区域，也就是神经元对输入数据的局部区域产生响应的范围。在深度学习中，感受野通常用于描述卷积神经网络中每一层的卷积核大小和步长，以及每个神经元对前一层的哪些神经元产生响应。在神经网络中，随着深度的增加，每个神经元的感受野也会逐渐变大，这意味着神经元能够响应更广泛的输入数据，从而提高了网络的表达能力和泛化能力。感受野的概念在计算机视觉、自然语言处理等领域都有广泛应用。</p>
<p>VGG 网络的基本出发点, 用小的卷积核来完成特征提取操作.</p>
<h1 id="19-递归神经网络架构"><a href="#19-递归神经网络架构" class="headerlink" title="19 递归神经网络架构"></a>19 递归神经网络架构</h1><p>Recurrent neural network, RNN, 主要用于自然语言处理中. 其会记录所有时刻的特征. 会考虑中间层之间的相关性. 前一层的输出会和下一层的输入一起参与运算.</p>
<p><img src="/../img/recurrent-neural-network.png" srcset="/img/loading.gif" lazyload></p>
<p>一般选择最后一层的输出结果.</p>
<p>LSTM, (Long Short-Term Memory) 是一种经典的循环神经网络（RNN）模型，它在RNN的基础上增加了门控机制，可以更好地处理长序列数据的依赖关系。</p>
<p>LSTM中的门控机制包括三个门：输入门、遗忘门和输出门。输入门控制输入数据的更新，遗忘门控制上一时刻的状态是否需要被遗忘，输出门控制输出的值是否需要被更新。通过这些门控制，LSTM可以有效地处理长序列数据，避免梯度消失或爆炸的问题。</p>
<p>LSTM的核心思想是通过记忆单元（memory cell）来维护历史信息，同时通过门控机制来控制历史信息的读写。记忆单元可以看作一个容器，用于存储历史信息，同时门控机制可以控制哪些信息需要被更新或遗忘。因此，LSTM在处理长序列数据时具有很好的记忆能力，可以有效地捕捉序列中的长期依赖关系，从而在很多任务上取得了很好的效果，比如机器翻译、语音识别、图像描述等领域。</p>
<p>其可以忘记一些网络.</p>
<p>其加入了一个控制参数 C 来控制模型的复杂度.</p>
<h1 id="20-自然语言处理-词向量模型-Word2Vec"><a href="#20-自然语言处理-词向量模型-Word2Vec" class="headerlink" title="20 自然语言处理 - 词向量模型 - Word2Vec"></a>20 自然语言处理 - 词向量模型 - Word2Vec</h1><p>Word2Vec是一种基于神经网络的词向量表示方法，它将词语映射到一个低维的向量空间中，从而将词语之间的语义关系转化为向量空间中的几何关系。</p>
<p>Word2Vec通过训练一个神经网络来学习词向量，其中输入是一个词语的上下文，输出是这个词语的向量表示。具体来说，Word2Vec有两种模型：CBOW（Continuous Bag-of-Words）和Skip-gram。CBOW模型将一个词语的上下文作为输入，预测这个词语本身，而Skip-gram模型则将一个词语作为输入，预测它的上下文。在训练过程中，Word2Vec通过最大化训练数据的概率来学习词向量，同时采用了负采样（negative sampling）等优化技术来加速训练和提高词向量的质量.</p>
<p>描述一个文本, 一般需要考虑多方面, 因此其维度较高, 一般为 50 ~ 300 维之间.</p>
<p>数据的维度越高, 能提供的信息也就越多, 从而计算结果的可靠性更高.</p>
<p>最基本的任务就是构建词向量.</p>
<h1 id="21-词向量模型通俗解释"><a href="#21-词向量模型通俗解释" class="headerlink" title="21 词向量模型通俗解释"></a>21 词向量模型通俗解释</h1>
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/AI/" class="category-chain-item">AI</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>神经网络-B站-Notes</div>
      <div>http://example.com/2023/07/08/神经网络-B站-Notes/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年7月8日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/07/15/%E6%B5%B7%E6%80%9D%E5%B5%8C%E5%85%A5%E5%BC%8F-Notes/" title="海思嵌入式-Notes">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">海思嵌入式-Notes</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/07/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE-Notes/" title="机器学习-吴恩达-Notes">
                        <span class="hidden-mobile">机器学习-吴恩达-Notes</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'zKurisu/comments-utterances');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Jie</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Orkarin</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
